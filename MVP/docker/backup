#!/bin/bash

# Move to project root
cd "$(dirname "$0")/.."

# Colors for output
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
RED='\033[0;31m'
NC='\033[0m' # No Color

echo -e "${YELLOW}Starting Docker build and deployment for the Audio Transcription App...${NC}"

# Check if Docker is installed and running
if ! docker info > /dev/null 2>&1; then
  echo -e "${RED}Error: Docker is not running or not installed${NC}"
  echo "Please install Docker and ensure the daemon is running."
  exit 1
fi

# Default ports (adjusted to avoid conflict with sound-saver-portal)
BACKEND_PORT=8000
FRONTEND_PORT=8080 # Changed to match docker-compose.yml host port mapping

# Check CUDA availability
USE_GPU=false
if command -v nvidia-smi > /dev/null 2>&1 && nvidia-smi > /dev/null 2>&1; then
  echo -e "${YELLOW}NVIDIA GPU with CUDA support detected.${NC}"
  echo -e "${YELLOW}Would you like to use the GPU? (y/N)${NC}"
  read -r response
  if [[ "$response" =~ ^[Yy]$ ]]; then
    USE_GPU=true
    echo -e "${GREEN}Configuring to use GPU...${NC}"
  else
    echo -e "${YELLOW}Proceeding with CPU only...${NC}"
  fi
else
  echo -e "${YELLOW}No CUDA-capable GPU detected. Using CPU...${NC}"
fi

# Check if ports are already in use
if lsof -i :$BACKEND_PORT > /dev/null 2>&1; then
  echo -e "${RED}Error: Port $BACKEND_PORT is already in use.${NC}"
  echo "Please free the port or edit docker-compose.yml to use a different backend port."
  exit 1
fi
if lsof -i :$FRONTEND_PORT > /dev/null 2>&1; then
  echo -e "${RED}Error: Port $FRONTEND_PORT is already in use.${NC}"
  echo "Please free the port or edit docker-compose.yml to use a different frontend port."
  exit 1
fi

# Create .env file if it doesn't exist
if [ ! -f backend/.env ]; then
  echo -e "${YELLOW}Creating sample .env file...${NC}"
  cat > backend/.env << 'EOF'
# Azure AI API Keys and Endpoints (for potential future use or specific models)
AZURE_AI_API_KEY=your_azure_ai_api_key_here
AZURE_AI_ENDPOINT=your_azure_ai_endpoint_here
AZURE_DEPLOYMENT_NAME=your_azure_ai_deployment_name_here

# Azure OpenAI API Keys and Endpoints (Primary for LLM agents)
AZURE_OPENAI_ENDPOINT=your_azure_openai_endpoint_here # e.g., https://your-resource.openai.azure.com/openai/deployments/your-deployment/chat/completions?api-version=YYYY-MM-DD
AZURE_OPENAI_API_KEY=your_azure_openai_api_key_here
OPENAI_API_VERSION=your_api_version_here # e.g., 2024-02-01
AZURE_OPENAI_DEPLOYMENT_NAME=your_azure_openai_deployment_name_here # e.g., gpt-4o-mini
EOF
  echo -e "${GREEN}Created .env file. Please edit it to add your actual API keys and settings.${NC}"
  echo -e "${YELLOW}Press Enter to continue after editing the .env file, or Ctrl+C to exit...${NC}"
  read
fi

# Build and start containers
echo -e "${YELLOW}Building and starting Docker containers...${NC}"
if [ "$USE_GPU" = true ]; then
  # Use both the base compose file and the GPU override file
  echo -e "${YELLOW}Starting containers with GPU support...${NC}"
  docker-compose -f docker/docker-compose.yml -f docker/docker-compose.gpu.yml up --build -d
else
  # Use only the base compose file for CPU mode
  echo -e "${YELLOW}Starting containers with CPU only...${NC}"
  docker-compose -f docker/docker-compose.yml up --build -d
fi

# Wait for services to start
echo -e "${YELLOW}Waiting for services to start...${NC}"
sleep 5

# Check if services are running
if docker-compose -f docker/docker-compose.yml ps | grep -q "Up"; then
  echo -e "${GREEN}Services are up and running!${NC}"
  
  # Get host IP (localhost on macOS, IP on Linux)
  if [[ "$OSTYPE" == "darwin"* ]]; then
    HOST_IP="localhost"
  else
    HOST_IP=$(hostname -I | awk '{print $1}')
  fi
  
  echo -e "${GREEN}===== Application URLs =====${NC}"
  echo -e "Frontend: ${GREEN}http://$HOST_IP:$FRONTEND_PORT${NC}"
  echo -e "Backend API: ${GREEN}http://$HOST_IP:$BACKEND_PORT${NC}"
  echo ""
  echo -e "${YELLOW}Use the following command to view logs:${NC}"
  echo "docker-compose logs -f"
  echo ""
  echo -e "${YELLOW}To stop the services:${NC}"
  echo "docker-compose down"
else
  echo -e "${RED}There was an issue starting the services.${NC}"
  echo "Please check the logs with: docker-compose logs"
fi
