1
00:00:00,530 --> 00:00:02,529
 Så att du ska slippa.

2
00:00:02,740 --> 00:00:04,740
 Hur är det läget med dig Fredrik?

3
00:00:04,740 --> 00:00:06,740
 Jag mår bra.

4
00:00:06,740 --> 00:00:09,300
 Jag är lite sur på AI för tillfället.

5
00:00:09,300 --> 00:00:13,300
 Men livet i övrigt är fantastiskt.

6
00:00:13,300 --> 00:00:15,300
 Härligt.

7
00:00:15,300 --> 00:00:23,300
 Man blir lite nyfiken på att du blir sur på AI som om det vore din fru.

8
00:00:23,300 --> 00:00:27,300
 Jag har grälat med AI om ekonomi.

9
00:00:27,300 --> 00:00:31,300
 Det är intressant när man gör den här podden.

10
00:00:31,300 --> 00:00:36,299
 så är det väldigt kul att sitta och testa olika tjänster.

11
00:00:36,299 --> 00:00:42,299
 Och oftast landar det faktiskt i att man blir rätt imponerad eller har kul längs vägen.

12
00:00:42,600 --> 00:00:49,600
 Men just den här veckan så har jag haft svårt att komma överens med de tjänster jag har testat.

13
00:00:49,600 --> 00:01:05,599
 Och det är, jag vet inte om du upplever det också, att det är lite av vilda västern där ute med företag som bygger AI-tjänster och det verkar inte alltid krävas jättemycket kompetens för att kasta upp något på nätet som man tar betalt för.

14
00:01:05,599 --> 00:01:14,599
 Det är väl min, kanske anledningen till att jag är lite irriterad på AI i stort idag.

15
00:01:14,599 --> 00:01:16,599
 idag. Men det går säkert över.

16
00:01:16,599 --> 00:01:27,599
 Jag fattar. Vi hör ju till en väldigt ovanlig del av AI-nyttjarna, alltså de som hoppar på allt.

17
00:01:27,599 --> 00:01:32,599
 Vi är lite som de här som klickar på alla länkar i alla mejl.

18
00:01:32,650 --> 00:01:49,650
 Vi kommer få göra en liten översyn. Jag försöker radera kontot på alla AI-tjänster som jag testar och försöker komma ihåg att stänga av subscription. Men vi får ta in en konsult och göra en översyn.

19
00:01:49,650 --> 00:01:51,450
 ganska säker på att båda våra datorer har någon

20
00:01:51,450 --> 00:01:54,450
 någon slags digital variant av ebola, minst.

21
00:01:54,450 --> 00:01:56,450
 Troligtvis.

22
00:01:56,450 --> 00:01:58,450
 Har du några nyheter idag?

23
00:02:00,000 --> 00:02:17,000
 Ett litet sorgligt besked för vissa kanske, det är att det här företaget Humane som gjorde den här AI-pinnen som kom förra våren, de kastar in handduken och säljer sina kvarvarande tillgångar till HP.

24
00:02:17,000 --> 00:02:23,000
 En AI-pin som man sätter på kroppen på något sätt och så lyssnar på allt man säger och ser allt man ser.

25
00:02:23,000 --> 00:02:34,000
 Exakt, och jag tror att tanken, eller marknadsföringen har gått ut lite på att man ska göra sig kvitt sitt skärmberoende och så ska man få den här fina AI-hjälpen ändå.

26
00:02:34,000 --> 00:02:42,000
 Det kanske var så att världen inte var mogen för det och att vi kommer se det i framtiden.

27
00:02:42,000 --> 00:02:56,000
 Men den här resan för dem har ju varit kantad av väldiga problem. Dels var ju den här nålen svindyr, den kostade 7-8000 kronor.

28
00:02:56,000 --> 00:02:58,000
 För en nål bara liksom?

29
00:03:00,000 --> 00:03:13,000
 Ja men exakt, och det är så här att den löser problem som du faktiskt bara kan lösa genom att stoppa ner handen i fickan och lösa det bättre genom att titta på din älskade skärm.

30
00:03:13,000 --> 00:03:21,000
 Jag blir inte jätteförvånad, men jag kan ha en uppskattning för att folk försöker.

31
00:03:21,000 --> 00:03:36,000
 Jag tror att det var Oracles vd och grundare Douglas Element som sa att om du inte skäms för din första lansering eller produkt i efterhand, då har du väntat för länge med att lansera den.

32
00:03:36,270 --> 00:03:41,270
 Och det är väl det vi ser också, att det är helt sjuka grejer som släpps där.

33
00:03:41,270 --> 00:03:43,270
 Och det är bara att åka med.

34
00:03:43,349 --> 00:03:46,349
 Ja, verkligen. Nu kommer jag att tänka på Woddler. Kommer du ihåg Woddler?

35
00:03:46,349 --> 00:03:50,349
 Ja, det var väl en förlaga till Netflix?

36
00:03:50,349 --> 00:03:54,349
 Ja, exakt. En tjänst som var en jättebra idé, streama video.

37
00:03:54,389 --> 00:03:59,590
 Men tyvärr, ni var lite tidiga för att folk hade fortfarande 28/8 modem.

38
00:04:00,000 --> 00:04:05,759
 Den kommer jag ihåg och den var inte så, jag hade en period när jag fick

39
00:04:05,919 --> 00:04:11,599
 körtelfeber och bara låg inne på sjukhus och det var rätt jobbigt men då hade jag faktiskt

40
00:04:11,599 --> 00:04:17,360
 Woddler som sällskap. Jag tyckte tjänsten funkade helt klockrent. Det var bara det att man glömt den här

41
00:04:17,360 --> 00:04:22,360
 detaljerna att de måste ha bra filmer i sitt utbud.

42
00:04:30,000 --> 00:04:36,439
 Okej, men det var det. Men jag kommer ihåg, jag fick en förhandsinvite till Voddler

43
00:04:36,600 --> 00:04:41,079
 och tänkte att det här kommer bli grymt. Men jag hade ju alldeles för dålig

44
00:04:41,240 --> 00:04:46,480
 uppkoppling. Den var lite tidig, men den var bra. Och så var det ett jättefult namn.

45
00:04:46,660 --> 00:04:48,660
 PIN, AI PIN.

46
00:04:48,660 --> 00:04:52,660
 Vi kommer väl kanske köpa ett par Meta sådana här RayBan wearables.

47
00:04:52,660 --> 00:04:54,660
 Den är ju väldigt populär.

48
00:04:55,120 --> 00:04:56,120
 Ja.

49
00:04:56,120 --> 00:05:00,120
 Det kan jag uppskatta ändå, tänket i det.

50
00:05:00,120 --> 00:05:04,120
 i det att ja, Ray-Ban, skitsnygga glasögon.

51
00:05:04,120 --> 00:05:10,120
 Att man utgår från vad folk vill ha på sig snarare än vad som går att göra.

52
00:05:10,120 --> 00:05:15,120
 Och det märker man ju också att Meta, de försöker gå den vägen.

53
00:05:15,120 --> 00:05:24,120
 Nu vet jag att Zuckerberg hade ju, de har den här prototypen som kostar typ hundratusen kronor att tillverka, så den kommer vi inte få se.

54
00:05:24,120 --> 00:05:26,120
 Men att man börjar i den änden såhär.

55
00:05:26,120 --> 00:05:28,120
 Vad vill folk ha på sig?

56
00:05:28,120 --> 00:05:34,120
 ser vi hur mycket teknik vi kan få in i det snarare än att vi gör asfula grejer som ingen vill ha.

57
00:05:34,120 --> 00:05:37,120
 Det är nog rätt smart. Bra tänkt.

58
00:05:37,579 --> 00:05:39,579
 Mycket bra.

59
00:05:39,579 --> 00:05:47,579
 Ja, men grymt. Då kanske vi väntar med Humanes AIP. Det var ju bra att vi inte köpte en sån.

60
00:05:47,579 --> 00:05:53,579
 Den kommer sluta fungera den 28 februari, så njut den här sista veckan.

61
00:05:53,579 --> 00:06:01,579
 Det stod att vissa funktioner kommer ändå funka, typ som att den berättar om batteriet på väg att ta slut.

62
00:06:01,720 --> 00:06:07,720
 Berätta om batteriet på väg att börja brinna som också har varit ett fall.

63
00:06:07,720 --> 00:06:13,720
 Ja, men det är värt 8000-7000 bara det, att ha en sån produkt.

64
00:06:13,720 --> 00:06:15,720
 Ja, verkligen.

65
00:06:15,720 --> 00:06:25,720
 Ja men kul. Min nyhet är Grock 3 har släppts. Alltså det träskmonstret Grock.

66
00:06:30,139 --> 00:06:36,139
 ny variant som ska vara ungefär lika smart som de

67
00:06:36,139 --> 00:06:39,139
 smartaste OpenAI-modellerna.

68
00:06:39,139 --> 00:06:43,139
 Det står här på någon sida som jag har varit inne på, på

69
00:06:43,139 --> 00:06:44,139
 Mashable.

70
00:06:44,139 --> 00:06:48,139
 Grock 3 is just as good as its rivals, but not good enough

71
00:06:48,139 --> 00:06:53,740
 to make you cancel your chat GPT subscription.

72
00:06:53,740 --> 00:06:55,740
 Så att, ja.

73
00:06:55,740 --> 00:06:57,740
 Spännande.

74
00:07:00,000 --> 00:07:03,000
 trött när jag pratar om det här.

75
00:07:03,040 --> 00:07:09,920
 Men vi har blivit lite bortskämda för att nu finns det rätt många jätte,

76
00:07:09,959 --> 00:07:16,319
 jättevälfinansierade stor techbolag som håller på och kämpar med sina

77
00:07:16,360 --> 00:07:20,480
 frontier models som de kallas.

78
00:07:20,480 --> 00:07:30,480
 De här modellerna som pushar gränsen för vad som är möjligt och hur smart en maskin kan vara.

79
00:07:30,480 --> 00:07:34,480
 Men de kommer ju med nya grejer varenda vecka.

80
00:07:34,480 --> 00:07:40,480
 Och är det inte Groc så är det ChatGPT som släpper en ny modell

81
00:07:40,480 --> 00:07:44,480
 eller så kommer DeepSeek eller så kommer Anthropic.

82
00:07:44,480 --> 00:07:46,480
 Alltså det tar aldrig slut.

83
00:07:46,589 --> 00:07:56,589
 En reflektion där också är att det är intressant att det känns som att de mäter de här

84
00:07:56,589 --> 00:08:04,589
 olika LLM:sens intelligens genom hur svåra och komplexa mattetal de kan lösa.

85
00:08:04,589 --> 00:08:13,589
 Jag vet också att man tränar på korsord och sånt där och ser just the reasoning capabilities.

86
00:08:13,589 --> 00:08:19,589
 Men det är också intressant hur platt det kan falla.

87
00:08:19,589 --> 00:08:22,589
 Den har jättesvårt att tolka bilder.

88
00:08:22,589 --> 00:08:30,430
 jag skulle göra en logga häromdagen med text i, och då bara, de är 

89
00:08:30,430 --> 00:08:37,429
 De är helt värdelösa på att stava rätt i bilder.

90
00:08:37,429 --> 00:08:47,429
 Och där tänker jag att man missar målet ganska mycket genom att, det kanske inte är kvantfysik som folk är ute efter, utan det är att de bara klarar det mest basala.

91
00:08:48,409 --> 00:08:50,409
 Det där är rätt intressant.

92
00:08:50,409 --> 00:08:54,409
 Det finns ju tjänster som...

93
00:08:54,409 --> 00:09:01,409
 Det finns bara en bildgenereringstjänst som klarar av att generera text.

94
00:09:01,409 --> 00:09:03,409
 Och det är...

95
00:09:03,409 --> 00:09:05,409
 Kommer du ihåg?

96
00:09:05,809 --> 00:09:08,809
 Ja, vad hette de?

97
00:09:08,809 --> 00:09:10,809
 där du gjorde din logga?

98
00:09:10,809 --> 00:09:14,809
 Nej, det var design.com. Den var ju också bra.

99
00:09:14,809 --> 00:09:18,809
 Ja, den klarade ju på ett sätt det också på något sätt.

100
00:09:18,809 --> 00:09:22,809
 Men Ideogram heter den.

101
00:09:22,809 --> 00:09:28,809
 Den genererar ju, det är text i bildgenerator som fixar text också.

102
00:09:30,000 --> 00:09:43,000
 Och sen så har vi character.ai som fixar att hålla ihop en konsekvent karaktär under en längre period.

103
00:09:43,000 --> 00:09:54,000
 Det är rätt kul för att de här två grejerna, att generera text i bild och det här med karaktärer, det fixar ju inte de här frontier models.

104
00:09:54,000 --> 00:09:58,519
 Jag använder ju Claude jättemycket för att skriva och sådär.

105
00:09:58,519 --> 00:10:11,519
 Och ska jag skriva någonting längre, då har Claude en helt fantastisk liten funktion där man kan fånga en tonalitet genom att ladda upp texter och sådär.

106
00:10:11,519 --> 00:10:17,600
 Och den håller den i ett tag, men sen glömmer den bort det.

107
00:10:17,600 --> 00:10:19,399
 Och som man märker, det smyger sig på bara.

108
00:10:19,399 --> 00:10:21,120
 Vänta nu, nu tycker jag inte du har den där

109
00:10:21,120 --> 00:10:30,879
 tonalitet som jag bad om. I processen så har den släppt den här karaktären då,

110
00:10:30,919 --> 00:10:34,399
 eller tonaliteten. Och då tänker jag bara så här:

111
00:10:34,399 --> 00:10:44,399
 Ska de lägga lite krut på att bara fixa de här grejerna, eftersom det uppenbarligen går att fixa. Ideogram och character har ju fixat det, även om de säkert...

112
00:10:44,399 --> 00:10:53,399
 Det är ju väldigt intressant, vi som bara skrapar på ytan av AI och inte alls kan så mycket om själva grundläggande tekniken.

113
00:10:53,399 --> 00:11:00,399
 Men också det här exemplet vi har sett när vi har testat att det är fel antal fingrar och sånt.

114
00:11:00,450 --> 00:11:06,450
 som man tycker borde vara en jätteenkel sak för dem att ställa in. När du gör en

115
00:11:06,450 --> 00:11:13,789
 Människor har fem fingrar, jag har inte sex fingrar.

116
00:11:13,789 --> 00:11:15,789
 Ja, men det är lite konstigt.

117
00:11:15,789 --> 00:11:21,789
 De lägger så mycket krut på att utveckla nya modeller.

118
00:11:21,789 --> 00:11:27,789
 Jag fattar det, för de har ett mål och det är AGI, alltså artificiell generell intelligens.

119
00:11:28,059 --> 00:11:31,059
 Och den som kommer fram dit först vinner typ.

120
00:11:31,059 --> 00:11:43,059
 Men på vägen så vore det kul om de inte skulle glömma oss vanliga konsumenter som vill generera fram människor med fem fingrar.

121
00:11:43,059 --> 00:11:45,059
 Ge oss det så är vi glada sen.

122
00:11:45,059 --> 00:11:48,059
 Med tryck på t-shirten.

123
00:11:48,059 --> 00:11:51,659
 Ja, det var väl nyheterna.

124
00:11:51,659 --> 00:11:54,659
 Nu har vi bashat av storbolagen, exakt.

125
00:11:54,659 --> 00:11:56,659
 Altman och allt vad de heter.

126
00:11:56,659 --> 00:11:58,659
 De kan...

127
00:11:59,059 --> 00:12:06,059
 De får bättra sig. Jag vågar inte säga någonting, det kommer de säkert förstöra för mig på något sätt.

128
00:12:06,139 --> 00:12:13,139
 Har du någon tjänst som du vill visa?

129
00:12:13,139 --> 00:12:16,139
 Jag har en tjänst men jag vill inte visa den.

130
00:12:16,190 --> 00:12:22,190
 Vi har ju pratat om det, och jag nämnde det tidigare också.

131
00:12:22,190 --> 00:12:30,350
 När man testar massa tjänster så har jag upptäckt att det vore bra om det

132
00:12:30,350 --> 00:12:38,350
 fanns motsvarande App Store för AI-tjänster, som är sanktionerade av någon högre makt.

133
00:12:38,350 --> 00:12:42,350
 Ungefär som Apple eller OpenAI.

134
00:12:42,350 --> 00:12:50,549
 För att det är så fruktansvärt lätt att skapa en AI-tjänst och bara stoppa ut den där ute.

135
00:12:50,549 --> 00:12:56,549
 Det vore bra med en expertrating-sajt.

136
00:12:56,549 --> 00:13:01,549
 Vi kommer inte göra det, men om det är någon som lyssnar så finns det ett behov där ute.

137
00:13:01,549 --> 00:13:09,549
 För att det är så jäkla lätt att bara skapa konton och så sitter man och slösar sin tid på skittjänster.

138
00:13:09,549 --> 00:13:11,549
 Vilket är lite det som jag har gjort den här veckan.

139
00:13:11,549 --> 00:13:20,549
 Okej, men apropå det, varför ska inte vi skapa en sån sida? Det är väl precis i linje med den här podden.

140
00:13:20,549 --> 00:13:27,549
 Jag tänker så här, vi ska göra det, men vi ska göra det på ett sätt som inte tar en massa tid.

141
00:13:27,549 --> 00:13:36,549
 Så jag tänker att vi gör någon bot som crawlar alla våra avsnitt och skapar.

142
00:13:36,549 --> 00:13:38,549
 Det där borde man ju kunna fixa i love.

143
00:13:38,549 --> 00:13:47,549
 Det är faktiskt en intressant idé som inte är alltför tekniskt utmanande att göra.

144
00:13:47,549 --> 00:13:49,549
 Vi kan skriva upp den på vår to-do-lista.

145
00:13:49,570 --> 00:13:51,570
 Men bra, innan du...

146
00:13:52,320 --> 00:13:59,320
 Eller om det är en skittjänst, ska vi kanske skita i att visa den så kan du förklara vad du har upplevt istället?

147
00:13:59,320 --> 00:14:02,320
 Nej, jag tycker jag ska visa den.

148
00:14:02,320 --> 00:14:05,379
 Du ska visa skittjänsten? Ja, annars förstår man ju inte.

149
00:14:05,379 --> 00:14:11,379
 Vi måste ju vara tydliga med vad som är skit. Nu börjar vi bli...

150
00:14:11,379 --> 00:14:15,379
 Jag tänkte på det när jag satt och testade den här.

151
00:14:15,379 --> 00:14:19,379
 Man vill ju någonstans att alla tjänster ska lyckas som vi testar.

152
00:14:19,379 --> 00:14:21,379
 Men vi testar tjänster.

153
00:14:21,379 --> 00:14:25,379
 Det är inte så att vi säger att nu ska vi få alla tjänster att lyckas.

154
00:14:25,490 --> 00:14:27,490
 Full disclosure. Exakt.

155
00:14:27,490 --> 00:14:34,490
 Innan du gör det, jag är väldigt nyfiken på hur din AI-index har gått.

156
00:14:34,490 --> 00:14:38,490
 Din daytrading-grej har gått.

157
00:14:38,490 --> 00:14:43,490
 Full disclosure Fredrik, jag vill veta. Hur mycket pengar har du förlorat?

158
00:14:43,490 --> 00:14:59,490
 Jag ligger 200 kronor back och det mesta av det är för att courtaget, min courtageklass, priset man betalar för att köpa och sälja aktier, den är för dyr för de små belopp jag tjänar.

159
00:14:59,490 --> 00:15:07,490
 Så jag är inne på att byta strategi, antingen börja satsa lite mer pengar eller ligga kvar lite längre i de här aktierna.

160
00:15:07,490 --> 00:15:11,490
 Men hur mycket satte du in?

161
00:15:11,669 --> 00:15:13,669
 Satte du in? 10 000.

162
00:15:13,669 --> 00:15:16,669
 Ja men det var ändå 10 000.

163
00:15:16,669 --> 00:15:19,669
 Jag tyckte ändå att det var, det låter ju ändå som en,

164
00:15:19,669 --> 00:15:24,669
 du borde kunna starta på 10 000 och göra din förmögenhet.

165
00:15:24,669 --> 00:15:31,669
 Ja, men problemet är att jag ligger på en courtageklass som är minst 70 kronor per affär.

166
00:15:31,669 --> 00:15:33,669
 Så då kan jag tänka att det behövs en ganska

167
00:15:33,940 --> 00:15:37,940
 stadig uppgång varje dag.

168
00:15:37,940 --> 00:15:44,899
 Vad blir det? Blir det 7 % eller 0,7 % i förlust?

169
00:15:44,950 --> 00:15:51,950
 Ja men exakt, så den måste vara uppe på en bra bit över en procent för att den ska kännas värt att göra.

170
00:15:51,950 --> 00:16:02,950
 Sen till AI:s försvar kan jag säga att de aktier jag köpt har på det stora hela gått upp, men inte på den nivån att det har varit lönsamt än.

171
00:16:03,769 --> 00:16:10,769
 Okej, så kurvan visar en positiv utveckling men courtaget drar ner det hela?

172
00:16:10,879 --> 00:16:20,879
 Ja, och det här kan ju jag ändra. Jag skulle kunna fixa så att jag har en, nu ska jag inte fastna i en courtage-diskussion, men det kan man ju ställa in också.

173
00:16:20,990 --> 00:16:29,990
 Men du har alltså betalat, vad blir det då, sju dagar gånger 70 spänn? Så 490 spänn i courtage?

174
00:16:29,990 --> 00:16:30,990
 Ja, precis.

175
00:16:31,360 --> 00:16:38,360
 Okej, jag fattar att det förstör din daytrading business lite grann.

176
00:16:38,360 --> 00:16:49,360
 Ja, och det är enkelt att fixa. Sen så drabbar det ju min övriga portfölj. Jag har inte gett upp. Jag tror att jag måste finkalibrera bara och tänka till lite.

177
00:16:49,539 --> 00:17:00,539
 Okej, bra. Förlåt att jag frågade, men jag tror att det är många där ute som har höga förhoppningar.

178
00:17:00,539 --> 00:17:04,539
 Okej, visa din dåliga AI-tjänst.

179
00:17:04,779 --> 00:17:13,779
 Men ja, jag kan bara börja med att berätta vad det är för tjänst. Det är för folk som är väldigt stressade.

180
00:17:13,779 --> 00:17:18,380
 De har många grejer som ligger varje dag som de måste ha tag i.

181
00:17:18,380 --> 00:17:20,380
 Kan du känna igen dig i det här Magnus?

182
00:17:20,380 --> 00:17:24,380
 ett stort moln av skit du måste göra?

183
00:17:30,000 --> 00:17:36,000
 Jag brukar vara rätt duktig på yin och yang, men jag har haft sjuka barn.

184
00:17:36,000 --> 00:17:40,000
 Det var framförallt det som förstör min planering lite grann.

185
00:17:40,000 --> 00:17:44,000
 Jag kan ändå fatta.

186
00:17:44,000 --> 00:17:50,819
 Den tjänst som jag har testat heter before sunset.

187
00:17:50,819 --> 00:17:53,819
 Och jag markerar, så du kan sätta igång i lugn och ro.

188
00:17:56,009 --> 00:18:00,009
 Hur är det, för att få ljud är det bara flik man kan dela eller hur?

189
00:18:00,190 --> 00:18:02,190
 Exakt.

190
00:18:02,190 --> 00:18:06,529
 Var noga med att bara beskriva det du ser.

191
00:18:06,529 --> 00:18:19,529
 Ja, det vi ser nu när jag delar min skärm här är ett flöde där man kan skapa att göra-listor och då är det uppdelat i arbete och personliga saker.

192
00:18:19,529 --> 00:18:25,529
 och för det här exemplet så har jag lagt in några arbets-to-dos

193
00:18:25,529 --> 00:18:36,529
 och det är spela in podcast, skriva lite copy till en kund, lära mig mer om Anything LLM som är en cool tjänst.

194
00:18:36,529 --> 00:18:41,809
 Sen skicka fakturor och sen så har jag skrivit på svenska förberedd föreläsning om AI.

195
00:18:41,849 --> 00:18:43,970
 Och så har jag lite personliga saker.

196
00:18:43,970 --> 00:18:49,970
 Jag och Magnus ska åka till fjällen. Jag ska förbereda en handlingslista.

197
00:18:49,970 --> 00:18:55,970
 Jag ska hjälpa ungarna med läxor och laga mat och så ska jag träna. Det är det jag ska hinna med idag är tanken.

198
00:18:56,430 --> 00:19:07,430
 Och hur kommer då AI in i det här? Jo, det här bygger lite på att det är en massa to-dos som jag inte har en fast tid för.

199
00:19:07,450 --> 00:19:20,450
 Okej, så då kan jag bland annat då plan my day, klicka på den och då får jag någon sån här time management mumbo jumbo.

200
00:19:20,450 --> 00:19:24,450
 Det finns olika metoder för hur man kan planera sin dag.

201
00:19:24,720 --> 00:19:30,720
 Eat the frog, att man tar den svåraste uppgiften först.

202
00:19:30,720 --> 00:19:34,720
 Vilken hemsk analogi.

203
00:19:34,720 --> 00:19:45,720
 Quick Wins, Complete Easy Tasks First, Smart Balance och Batch Similar, det är att man parar ihop liknande uppgifter.

204
00:19:45,720 --> 00:19:49,720
 Och sen Task Variety, Switch Between Different Tasks.

205
00:19:49,720 --> 00:19:52,720
 Jag kan ta Batch Similar om man klickar på den.

206
00:19:52,720 --> 00:19:55,720
 Då ser vi att AN jobbar här.

207
00:19:55,720 --> 00:20:01,720
 Vilken trevlig liten animering som kom där. Det liksom sprätte iväg någonting.

208
00:20:01,720 --> 00:20:11,920
 och då ser vi att då har AN tagit sig friheten att planera exakt i vilken ordning jag ska göra det här.

209
00:20:11,920 --> 00:20:20,920
 Så det här är alltså en sorteringsapp. Den sorterar dina to-dos på ett sätt som är lite oklart.

210
00:20:20,920 --> 00:20:24,920
 Bland annat gissar jag.

211
00:20:24,920 --> 00:20:27,920
 Sen ska jag visa också en annan AI-funktion.

212
00:20:27,920 --> 00:20:34,920
 Man kan gå in på de här punktlistorna och klicka.

213
00:20:34,920 --> 00:20:38,920
 Jag har planerat att det tar en halvtimme.

214
00:20:38,920 --> 00:20:41,920
 Sen kan jag markera hur lång tid det tar och så vidare.

215
00:20:41,920 --> 00:20:43,920
 Jag startar tiden när jag börjar.

216
00:20:43,920 --> 00:20:48,440
 Men sen då om jag vill använda AI även här

217
00:20:48,440 --> 00:20:54,440
 Ska klicka på AI-assistenten och klicka på Create Subtask.

218
00:20:54,440 --> 00:20:59,440
 Och då styckar den upp den här to-do-listan i flera to-dos.

219
00:20:59,440 --> 00:21:02,440
 äter elefanten i små delar.

220
00:21:02,440 --> 00:21:04,440
 I ethefrog-tanken här.

221
00:21:04,490 --> 00:21:08,490
 Precis, och det här är väl, ja...

222
00:21:08,950 --> 00:21:11,950
 Jag fattar, jag fattar.

223
00:21:11,950 --> 00:21:14,950
 Det är väl inte så dumt om man...

224
00:21:14,950 --> 00:21:17,950
 Jag tänker så här.

225
00:21:17,950 --> 00:21:21,950
 Prokrastinering, att skjuta saker på framtiden.

226
00:21:21,950 --> 00:21:25,950
 Det är väl det vi är bäst på, vi människor.

227
00:21:25,950 --> 00:21:29,950
 När man har en fullsmockad dag, man måste göra hundra grejer.

228
00:21:29,950 --> 00:21:37,950
 Och sen så har man någon liten tjänst som kan dela upp en svår uppgift i mindre uppgifter. Det är väl ganska smart ändå?

229
00:21:38,190 --> 00:21:54,190
 Säkert. Men det som jag känner, man känner ganska snabbt i det här är att bara sköta hela den här skiten i en till uppgift i sig som tar tid och fokus från det man egentligen ska göra.

230
00:21:54,190 --> 00:21:58,190
 Du tror inte riktigt på själva grundidén här hör jag.

231
00:22:00,000 --> 00:22:04,000
 Nej, livet är ju sällan så här.

232
00:22:04,000 --> 00:22:08,000
 Sen vet jag att man kan koppla den här mot sin egen kalender.

233
00:22:08,000 --> 00:22:15,000
 Så fasta inbokningar i kalendern, då fattar den det.

234
00:22:15,109 --> 00:22:21,109
 Men sen ska jag visa en sista funktion här också som jag tyckte var lite rolig.

235
00:22:21,190 --> 00:22:24,190
 "Focus with Oasis" klickar vi på nu.

236
00:22:24,190 --> 00:22:24,690
 Vad är det då?

237
00:22:24,690 --> 00:22:36,690
 Så då kommer jag, istället för att se hela flödet och bli alldeles stressad så kan jag få bara den här checklistan med en bakgrund som är en vacker stuga.

238
00:22:36,690 --> 00:22:38,690
 Genererad bild.

239
00:22:38,690 --> 00:22:42,690
 Och sen så har jag ett litet inspirationscitat här.

240
00:22:42,690 --> 00:22:44,990
 I have everything I need within me to succeed.

241
00:22:44,990 --> 00:22:47,990
 Så det är en digital fortune cookie som dyker upp här.

242
00:22:47,990 --> 00:22:51,990
 Och det här är också viktigt.

243
00:22:51,990 --> 00:22:56,150
 att jag kan få lite meditationsmusik

244
00:22:56,150 --> 00:22:59,150
 Medan jag bockar av min lista.

245
00:23:00,000 --> 00:23:08,140
 Skulle man kunna säga, och du har fireplace sound också.

246
00:23:08,140 --> 00:23:23,140
 Jag känner så här, om man har sådant liv att man behöver den här appen, då är troligtvis inte den här appen lösningen på det här.

247
00:23:23,190 --> 00:23:29,190
 Ditt liv är väl det som är rådet.

248
00:23:30,000 --> 00:23:42,000
 Om man ska dela in tjänster i nice to have och need to have så är det väl det här, det är så mycket nice to have. Om det ens är nice to have som sagt.

249
00:23:42,000 --> 00:23:45,720
 Jag tänkte säga en tredje kategori här, &lt;i&gt;not&lt;/i&gt; nice&lt;/i&gt;.

250
00:23:45,720 --> 00:23:49,480
 Jag tycker det här verkar sortera in där.

251
00:23:49,480 --> 00:23:56,480
 Ja, och nu ska inte vi trampa stressade folk på tårna som verkligen går igång på det här.

252
00:23:56,480 --> 00:23:57,480
 Ja, det här behöver jag.

253
00:23:57,480 --> 00:24:07,480
 Men om det är någon som gillar det här, gå in och skaffa tjänsten och återkoppla till mig sen om det har ändrat ert liv.

254
00:24:07,480 --> 00:24:10,480
 Men ja, that's it for me ungefär.

255
00:24:11,099 --> 00:24:17,099
 Jag tyckte att det var en snygg UX på den här sidan.

256
00:24:17,099 --> 00:24:18,099
 Det tycker jag med.

257
00:24:18,099 --> 00:24:20,099
 De hade en bra UX-designer.

258
00:24:20,099 --> 00:24:22,099
 Det tyckte jag var något positivt.

259
00:24:22,210 --> 00:24:27,210
 Bra. Lyckades du avsluta abonnemanget?

260
00:24:27,210 --> 00:24:32,210
 Det ska jag göra nu. Det har ändå kostat mig 120 kronor.

261
00:24:32,210 --> 00:24:36,000
 Okej.

262
00:24:36,000 --> 00:24:38,000
 Härligt.

263
00:24:38,000 --> 00:24:41,000
 Fredrik, kan du fixa din mick?

264
00:24:41,000 --> 00:24:43,000
 Ja.

265
00:24:43,000 --> 00:24:53,730
 Okej, jag har lite olika grejer här den här dagen.

266
00:24:53,730 --> 00:25:03,730
 För det första så tänkte jag, jag kom på det, jag höll på att förbereda en föreläsning här för ett gäng som jag ska hålla.

267
00:25:03,730 --> 00:25:13,730
 Och då gick jag igenom allt jag vet om ChatGPT och kom på att jag kan rätt mycket om hur det funkar.

268
00:25:13,730 --> 00:25:20,410
 Och jag vet vissa tricks som kanske inte alla vet.

269
00:25:20,410 --> 00:25:24,089
 Så jag tänkte börja med, eftersom vi har så många lyssnare nu för tiden,

270
00:25:24,089 --> 00:25:26,089
 och alla är väl på olika nivå,

271
00:25:26,089 --> 00:25:31,210
 men jag tänkte i alla fall dela med mig av fem snabba om ChatGPT till att börja med.

272
00:25:31,210 --> 00:25:36,210
 Och sen tänkte jag gå in på mina ganska roliga tjänster som jag testat.

273
00:25:36,210 --> 00:25:41,210
 Så vi kan väl börja där.

274
00:26:01,579 --> 00:26:18,579
 Okej, den första grejen som jag har är egentligen att ChatGPT kan skapa Excel och PowerPoint, alltså filerna.

275
00:26:18,579 --> 00:26:24,579
 Ofta kan ChatGPT skapa det mesta, spara i Word eller PDF.

276
00:26:24,579 --> 00:26:27,579
 Så det är en ganska bra grej att känna till.

277
00:26:27,579 --> 00:26:29,579
 Blir det bra också?

278
00:26:30,049 --> 00:26:34,049
 Kan man inte riktigt säga?

279
00:26:34,049 --> 00:26:45,049
 Jag gjorde en liten fråga.

280
00:26:45,049 --> 00:26:51,049
 Jag sa till den att skapa en presentation med två bilder om AGI.

281
00:26:51,049 --> 00:26:56,049
 Och det den gör då, eftersom den är textmodell till att börja med,

282
00:26:56,230 --> 00:26:59,230
 Då beskrev den så här: Bild 1, vad är AGI?

283
00:26:59,230 --> 00:27:03,230
 Och sen så säger den bildinnehåll och speaker notes.

284
00:27:04,650 --> 00:27:08,650
 Och sen så bad jag den bara såhär, få in bilderna i en PowerPoint.

285
00:27:08,650 --> 00:27:15,650
 Och då som du ser här så sa den såhär, jag har skapat en PowerPoint-presentation om AGI, du kan ladda ner den här.

286
00:27:15,650 --> 00:27:17,650
 Och då gjorde jag det.

287
00:27:17,650 --> 00:27:20,650
 Och då blev det så här.

288
00:27:20,670 --> 00:27:22,670
 Wow.

289
00:27:22,940 --> 00:27:25,940
 Så det blir liksom en...

290
00:27:26,119 --> 00:27:33,119
 Det blev en PowerPoint-presentation, men det är fortfarande så här, man får göra resten själv.

291
00:27:33,119 --> 00:27:41,119
 Det är som att du skulle ha en 14-årig praoelev som du ber göra en PowerPoint.

292
00:27:41,170 --> 00:27:49,170
 Ja, precis. Men fördelen med det här, om man nu ser det positivt, så är det ju att du får in de här sliderna.

293
00:27:49,170 --> 00:27:53,170
 Du kanske har skapat 30 slides och då får du in all information på sliderna.

294
00:27:53,170 --> 00:27:59,170
 Sen kan du typ i Canva, som är min favorittjänst för att skapa presentationer.

295
00:27:59,170 --> 00:28:03,170
 Eller Powerpoint om du nu vill jobba med det.

296
00:28:03,170 --> 00:28:08,170
 Så då kan man liksom gå in och lägga till, göra om de här på olika sätt.

297
00:28:08,170 --> 00:28:13,170
 Har inte du testat Canvas-integration mot ChatGPT också?

298
00:28:13,170 --> 00:28:20,170
 Ja, precis. Den är inte jättebra, kan jag säga.

299
00:28:20,170 --> 00:28:23,170
 Så den vill jag inte presentera här.

300
00:28:23,349 --> 00:28:27,349
 Så det var en grej.

301
00:28:27,349 --> 00:28:38,349
 Sen som du ser här så bad jag den skapa en bild som inspireras av detta i renässansstil.

302
00:28:38,430 --> 00:28:46,430
 Jag tycker inte att DAL-E, alltså ChatGPTs bildgenereringsfunktion, är speciellt bra.

303
00:28:46,799 --> 00:28:50,799
 Det här är ju, ja, jag vet inte.

304
00:28:50,799 --> 00:28:59,799
 Men tricket som jag, för det är många som använder sig av, det ser man på LinkedIn om inte annat, att det är många som använder sig av ChatGPT för att generera bilder.

305
00:28:59,799 --> 00:29:04,799
 Och då kan det vara bra, eftersom det är svårt att generera fram bra bilder.

306
00:29:04,799 --> 00:29:08,799
 Då kan det vara bra att veta att om man klickar på en bild så här,

307
00:29:08,799 --> 00:29:12,559
 Nu klickar jag på den. Då kommer den upp i ett annat läge.

308
00:29:12,559 --> 00:29:20,259
 Och då finns det en liten ikon som ser ut som en pensel med en pil runt.

309
00:29:20,259 --> 00:29:28,259
 Och väljer man den, då kan man faktiskt gå in och promta om bara en liten grej.

310
00:29:28,259 --> 00:29:40,579
 Så om jag säger att jag vill byta ut den här mot en groda, byt ut denna mot en groda skriver jag.

311
00:29:40,579 --> 00:29:44,579
 Ganska likt som det funkar i Photoshop nu egentligen.

312
00:29:44,579 --> 00:29:50,579
 Ja, exakt. Sen så tror jag eventuellt att Photoshop ser lite bättre ut.

313
00:29:50,579 --> 00:29:52,579
 Men då ska vi se.

314
00:29:52,579 --> 00:29:57,019
 Och ja.

315
00:29:59,180 --> 00:30:01,180
 Jobbar den eller vad händer?

316
00:30:01,960 --> 00:30:04,960
 Jag tycker inte att jag ser att den jobbar ens.

317
00:30:05,460 --> 00:30:09,279
 Försöker jag?

318
00:30:10,029 --> 00:30:23,980
 Och då jobbar den här och nu ska den byta ut roboten mot en groda och det gjorde den som du ser.

319
00:30:23,980 --> 00:30:26,980
 Men den har också gjort om hela bilden?

320
00:30:26,980 --> 00:30:28,980
 Det har den ju i och för sig gjort.

321
00:30:28,980 --> 00:30:36,980
 Nu tänkte jag försvara ChatGPT, den gjorde precis tvärtom mot vad den gjorde.

322
00:30:36,980 --> 00:30:38,980
 Skitsamma.

323
00:30:38,980 --> 00:30:40,980
 Nu får de skämmas.

324
00:30:40,980 --> 00:30:42,980
 Men den funkar ibland.

325
00:30:42,980 --> 00:30:44,980
 Den funkar säkert.

326
00:30:44,980 --> 00:30:46,980
 Säkert hälften av gångerna.

327
00:30:46,980 --> 00:30:48,980
 Den finns det i alla fall.

328
00:30:48,980 --> 00:30:54,980
 På tal om att hålla karaktär längre tid.

329
00:30:55,960 --> 00:30:57,960
 Ja, exakt.

330
00:31:00,180 --> 00:31:04,180
 Hur mycket pengar de har lagt i det här så är det ändå rätt ofta.

331
00:31:04,180 --> 00:31:11,180
 Man får ju vara ganska snäll och gulla lite med ChatGPT ibland för att det ska bli som man vill.

332
00:31:11,680 --> 00:31:18,680
 Men, okej, men man kan, där kan man göra, ni får testa själva.

333
00:31:18,680 --> 00:31:32,680
 Sen så, det kanske jag har nämnt i podden, men om man väljer, alltså här uppe finns en modellväljare. Så du kan välja olika modeller.

334
00:31:32,759 --> 00:31:38,759
 Och den här modellväljaren, Sam Altman, han har ju sagt att de hatar den.

335
00:31:38,759 --> 00:31:40,759
 Alltså jag hatar den också.

336
00:31:40,759 --> 00:31:42,759
 Varför ska jag behöva välja modeller?

337
00:31:42,759 --> 00:31:46,759
 Och det kommer i nästa release.

338
00:31:46,759 --> 00:31:50,759
 Att den automatiskt fattar vilken modell som är bäst för prompten.

339
00:31:50,759 --> 00:31:54,680
 Ja, den kommer försvinna under säkert det här halvåret.

340
00:31:54,680 --> 00:32:00,680
 Men ChatGPT 4.0 med schemalagda aktiviteter, det kanske vi har gått igenom.

341
00:32:00,680 --> 00:32:06,680
 Men bara lite snabbt, man kan då be ChatGPT påminna en om olika saker.

342
00:32:06,680 --> 00:32:13,680
 Du kan sätta påminnelser, typ göra konkurrentanalys eller någonting.

343
00:32:13,680 --> 00:32:15,680
 Skicka till mig varje...

344
00:32:15,680 --> 00:32:20,680
 Jag skickar det här med den här prompten varje dygn.

345
00:32:20,680 --> 00:32:24,680
 Så det är en jäkligt bra grej, tycker jag.

346
00:32:24,680 --> 00:32:29,680
 Den stora frågan är, kan den här påminnelsen komma in i Before Sunset också?

347
00:32:30,000 --> 00:32:42,000
 Ja, exakt. För oss är det här superbasic, men det är nog inte det för alla märkte jag när jag presenterade det här sist.

348
00:32:42,000 --> 00:32:44,000
 Men du kan också ladda upp filer.

349
00:32:44,140 --> 00:32:47,140
 Så du kan ladda upp en lokal fil.

350
00:32:47,250 --> 00:32:50,250
 Nu laddade jag upp en bild på dig.

351
00:32:50,250 --> 00:32:52,250
 Ingenting funkar med ChatGPT nu.

352
00:32:52,250 --> 00:32:58,250
 Du kan ladda upp ett pdf-dokument och be den göra saker med det.

353
00:32:58,250 --> 00:33:03,250
 Sammanställa som en Excel eller fråga om dokumentets innehåll.

354
00:33:03,250 --> 00:33:10,250
 Så det var fem små snabba ChatGPT-tips innan jag går vidare i min lilla...

355
00:33:10,250 --> 00:33:12,250
 Var det fem tips verkligen?

356
00:33:12,250 --> 00:33:18,250
 Nej, det var bara fyra. Men det spelar väl ingen roll? Jag trodde inte att någon skulle...

357
00:33:18,250 --> 00:33:24,250
 Kör lite den här fingerdefekten.

358
00:33:24,250 --> 00:33:29,250
 Jag är precis som AI, jag klarar inte av fem, fyra eller sex.

359
00:33:30,000 --> 00:33:33,000
 Fyra tips. Okej, men jag säger ett tips till då.

360
00:33:33,000 --> 00:33:35,000
 Så att det blir fem.

361
00:33:35,000 --> 00:33:40,000
 Då kan jag nämligen skriva det i podden, vad den heter, eller beskrivningen.

362
00:33:40,000 --> 00:33:43,000
 Okej, mitt tips, nästa tips, det är det här.

363
00:33:43,000 --> 00:33:45,000
 Klickar du på ditt...

364
00:33:45,000 --> 00:33:49,000
 Alltså den inställningsfliken.

365
00:33:49,000 --> 00:33:54,000
 Då finns det lite olika saker här.

366
00:33:54,000 --> 00:33:56,000
 Då kan man faktiskt anpassa chatt-GPT.

367
00:33:56,940 --> 00:34:03,940
 Och man kan skriva så här, hur ska chatt-GPT tilltala dig?

368
00:34:04,339 --> 00:34:09,340
 Det kan man skriva i här.

369
00:34:09,340 --> 00:34:18,340
 Här kan man också hitta ChatGPT's minne under inställningar.

370
00:34:18,340 --> 00:34:25,650
 Och anpassning och minne.

371
00:34:25,650 --> 00:34:27,650
 Så hantera minnen.

372
00:34:30,000 --> 00:34:38,000
 Och som du ser så har ChatGPT lärt sig en hel del om mig här under de åren som jag har använt det.

373
00:34:38,000 --> 00:34:45,000
 Så den sparar vissa grejer som den tycker att det här är bra att veta om Magnus.

374
00:34:45,000 --> 00:34:48,000
 Tänk om Spotify hade den här funktionen.

375
00:34:48,000 --> 00:34:53,000
 Jag minns när barnen var små så råkade vi lyssna på Marcus &amp; Martinus en sommar.

376
00:34:53,000 --> 00:34:59,000
 Och sen så var alla mina förslag i Discover Weekly, det var norska låtar.

377
00:34:59,000 --> 00:35:02,000
 Jag kunde liksom inte ta bort det på något sätt.

378
00:35:02,000 --> 00:35:05,000
 Det här är väl briljant om man bara kan.

379
00:35:05,000 --> 00:35:07,000
 Men.

380
00:35:07,210 --> 00:35:09,210
 Men ser jag nu.

381
00:35:09,210 --> 00:35:13,210
 Has an interest in hummingbirds.

382
00:35:13,210 --> 00:35:21,210
 Okej, här kan man i alla fall...

383
00:35:21,210 --> 00:35:25,210
 Det är därför vi ska gå in på inkognitomode när vi ska chatta.

384
00:35:25,210 --> 00:35:27,210
 Ja, verkligen.

385
00:35:27,210 --> 00:35:30,210
 Så jag raderar.

386
00:35:30,210 --> 00:35:32,210
 Glömmer.

387
00:35:32,210 --> 00:35:34,210
 Intressant, nu kommer det ord.

388
00:35:34,210 --> 00:35:41,210
 Wants me to act as a real time translator. Translating their spanish into Portugese or spanish word for word.

389
00:35:41,320 --> 00:35:43,320
 Okej.

390
00:35:43,559 --> 00:35:47,559
 preferes that I wait until they finish talking before responding.

391
00:35:47,559 --> 00:35:49,559
 Den är inte klockren.

392
00:35:49,559 --> 00:35:53,559
 ChatGPT framstod som en sämre dag än nu.

393
00:35:53,559 --> 00:35:56,559
 Nu har jag tyvärr gjort sex tips.

394
00:35:56,559 --> 00:36:00,559
 Men jag kommer sammanfatta det till fem när jag sammanfattar det här sen.

395
00:36:00,559 --> 00:36:04,559
 Skönt att jag kan dra ner dig i min AI-blues idag också.

396
00:36:04,559 --> 00:36:10,559
 Ja, exakt. Sluta med det. Nu ska jag visa något riktigt coolt här.

397
00:36:11,250 --> 00:36:18,250
 Jag vet inte om du, vi har ett avsnitt där vi skriver i alla fall i avsnittet att vi väcker gamla minnen.

398
00:36:18,250 --> 00:36:21,250
 Ja, det var min ambition i alla fall.

399
00:36:21,250 --> 00:36:25,250
 Men du misslyckades ganska hårt med det.

400
00:36:25,250 --> 00:36:28,250
 Jag tror, jag kommer inte ihåg vad den tjänsten hette.

401
00:36:28,250 --> 00:36:30,250
 Det gör jag faktiskt inte.

402
00:36:30,250 --> 00:36:36,250
 För att jag tänkte så här, nej, men det här måste funka alltså.

403
00:36:36,250 --> 00:36:38,250
 AI ska klara av det här.

404
00:36:38,250 --> 00:36:44,250
 Så jag försökte hitta den som verkade bäst.

405
00:36:44,250 --> 00:36:48,250
 Och den heter då alltså Deep Nostalgia.

406
00:36:49,230 --> 00:36:51,230
 Hit me baby.

407
00:36:51,230 --> 00:36:53,230
 Deep Nostalgia AI.

408
00:36:53,230 --> 00:37:01,230
 Old photos into videos bring image to life. Så jag gick in. Här får man också pröjsa först.

409
00:37:01,230 --> 00:37:04,349
 Jag tror att det kan ha varit den där jag testade.

410
00:37:04,349 --> 00:37:09,150
 Det ska bli jättespännande att se om den är bättre än övriga.

411
00:37:09,150 --> 00:37:15,150
 Jag tog ett basic-abonnemang, 15,90 dollar per månad.

412
00:37:15,150 --> 00:37:17,150
 Nej, vet du vad?

413
00:37:17,150 --> 00:37:19,150
 Du har inte köpt den här?

414
00:37:19,150 --> 00:37:21,150
 Nej men vad luriga de är.

415
00:37:21,929 --> 00:37:24,929
 Pro-abonnemanget visas först.

416
00:37:25,840 --> 00:37:31,840
 Och sen kommer Basic-abonnemanget. Så jag råkade nog ta Pro-abonnemanget.

417
00:37:31,840 --> 00:37:33,840
 Roligt.

418
00:37:33,840 --> 00:37:35,840
 Jäklar.

419
00:37:35,840 --> 00:37:37,840
 Det här vill man inte ens lära sig av.

420
00:37:37,840 --> 00:37:38,840
 Så där vill man inte ha det.

421
00:37:38,840 --> 00:37:39,840
 Strunt samma.

422
00:37:39,840 --> 00:37:42,840
 Här finns det lite olika grejer.

423
00:37:42,840 --> 00:37:44,840
 Free tools.

424
00:37:44,840 --> 00:37:46,840
 Magic tools.

425
00:37:46,840 --> 00:37:50,840
 Free tools gör ditt foto bättre.

426
00:37:50,840 --> 00:37:52,840
 Enhanced photo.

427
00:37:52,840 --> 00:37:57,840
 Du kan skapa färger till svartvita foton och sånt där.

428
00:37:57,840 --> 00:37:59,840
 Jag har inte testat dem.

429
00:37:59,860 --> 00:38:01,860
 Sen har vi magic tools.

430
00:38:02,099 --> 00:38:04,099
 Och här finns det lite olika grejer.

431
00:38:04,099 --> 00:38:07,300
 Det finns väldigt mycket olika tools här i alla fall.

432
00:38:07,300 --> 00:38:12,940
 Det mest intressanta är ju då Fast Video Generator, Image to Video. Jag vet

433
00:38:12,940 --> 00:38:21,300
 faktiskt inte skillnad mellan dem. AI hug, AI dance, AI kissing, AI kang-fu, AI lip-sync.

434
00:38:21,300 --> 00:38:23,599
 Kan inte du köra AI-kang-fu på din gammelfarmor?

435
00:38:24,030 --> 00:38:36,030
 Faktum är att jag har gjort lite, för det tar ju en liten stund, det tar typ fem minuter att generera fram de här grejerna. Så jag har faktiskt gjort lite olika som jag tänkte demonstrera nu faktiskt.

436
00:38:36,030 --> 00:38:41,030
 Och för er som lyssnar så är det här en videopodd som finns på Spotify.

437
00:38:41,030 --> 00:38:44,030
 Vi finns på alla andra plattformar också, men då är det bara audio.

438
00:38:44,030 --> 00:38:48,030
 Så för er som sitter i bilen nu, då kommer det här.

439
00:38:48,030 --> 00:38:51,030
 Ni får skippa om ni vill.

440
00:38:51,300 --> 00:38:53,300
 För nu kommer en del video här.

441
00:38:53,300 --> 00:38:56,099
 Vi ska försöka förklara i bästa förmåga.

442
00:38:56,099 --> 00:38:58,099
 Så jag skriver här My videos.

443
00:38:58,099 --> 00:39:00,099
 Klicka på den.

444
00:39:00,099 --> 00:39:04,099
 Och här har jag nu rätt många videos.

445
00:39:04,099 --> 00:39:07,099
 Så då började jag ju med de uppenbara.

446
00:39:07,099 --> 00:39:10,099
 Jag har ju ganska gamla släktingar.

447
00:39:10,099 --> 00:39:15,099
 De finns ju inte längre, de som föddes på 1800-talet.

448
00:39:15,099 --> 00:39:22,099
 Men jag hade en väldigt gammal pappa, så min farfar föddes typ 1875.

449
00:39:22,099 --> 00:39:24,099
 Oj, oj, oj.

450
00:39:24,099 --> 00:39:31,099
 Så det finns ju bara bilder, svartvita såklart.

451
00:39:31,099 --> 00:39:38,099
 Så jag började egentligen med att, här är en bild på min farfar när han står 1919 i Brasilien.

452
00:39:38,239 --> 00:39:40,239
 Gud vad han ser elegant ut.

453
00:39:40,380 --> 00:39:46,380
 Ja, verkligen. Han står vid en stor trappa. Jag tror att han bodde i det där huset.

454
00:39:46,380 --> 00:39:48,380
 Mussolini skulle kunna bo där?

455
00:39:48,840 --> 00:39:55,840
 Ja, verkligen. Han var duktig på det han gjorde.

456
00:39:55,840 --> 00:40:01,840
 Så då laddade jag upp den här bilden på honom och sen så...

457
00:40:01,840 --> 00:40:06,179
 Jag borde ju visa det också.

458
00:40:06,179 --> 00:40:10,179
 Jag visar det här.

459
00:40:10,179 --> 00:40:13,179
 Man droppar en bild.

460
00:40:13,179 --> 00:40:16,179
 Den får vara max 4,5 meg, vilket var ett problem.

461
00:40:16,179 --> 00:40:26,179
 problem och det måste vara JPG, PNG, alltså de här vanliga. Det får alltså inte vara Heik som är det filnamnet som...

462
00:40:26,179 --> 00:40:28,179
 Jag fanns här under.

463
00:40:28,389 --> 00:40:30,389
 Ja, verkligen. Alltså jag fattar inte det här.

464
00:40:30,389 --> 00:40:33,389
 Heik. Ingen klarar av Heik, men strunt samma.

465
00:40:33,389 --> 00:40:44,389
 Sen så får man en prompt, animate this image, bring it to life with subtil movements while presurning the original features.

466
00:40:44,500 --> 00:40:51,500
 Här kan man också Suggest Prompt för att det är svårt att komma på promptskärm och sen Optimize Prompt.

467
00:40:51,500 --> 00:40:55,500
 Och sen kan man ju visa hur mycket man vill att den ska följa prompten.

468
00:40:55,500 --> 00:40:58,500
 Och så genererar man och det kostar en credit.

469
00:40:58,900 --> 00:41:01,900
 Du kan göra 5 sekunder eller 10 sekunder.

470
00:41:01,900 --> 00:41:04,900
 Så det är ganska straight forward.

471
00:41:05,719 --> 00:41:12,719
 Så jag hoppar tillbaka till mina videos och så ska du få se min gamla farfar komma.

472
00:41:13,500 --> 00:41:16,500
 Come to life. Så jag klickar på play nu.

473
00:41:16,639 --> 00:41:21,079
 Och då ser du att...

474
00:41:21,739 --> 00:41:22,739
 Ja, vad var det du sa?

475
00:41:22,739 --> 00:41:26,739
 Du får nog köra igen för jag såg väldigt hackigt.

476
00:41:26,739 --> 00:41:31,840
 Just det.

477
00:41:32,369 --> 00:41:34,369
 Vad gör han där med sin hatt?

478
00:41:34,369 --> 00:41:39,369
 Han stoppar in ett papper ovanpå hatten.

479
00:41:39,369 --> 00:41:42,369
 Som en ganska vanlig företeelse 1920.

480
00:41:42,369 --> 00:41:44,369
 Ja, verkligen.

481
00:41:44,369 --> 00:41:46,369
 Så det var lite kul. Han rörde sig.

482
00:41:46,369 --> 00:41:50,369
 En bild på min farmor som sitter och spelar piano.

483
00:41:50,369 --> 00:41:56,369
 Det är fint, eftersom jag sitter och spelar.

484
00:41:56,369 --> 00:41:59,369
 Så nu sätter jag igång henne här.

485
00:42:01,590 --> 00:42:03,590
 Det där var ju coolt.

486
00:42:03,699 --> 00:42:06,699
 Alltså grejen är att det är coolt, men...

487
00:42:06,699 --> 00:42:09,980
 Det ser inte alls ut som din farmor.

488
00:42:09,980 --> 00:42:12,980
 Nej, det började... Alltså jag vet inte. Kanske.

489
00:42:12,980 --> 00:42:16,980
 Till slut blev hon ju asiatisk.

490
00:42:16,980 --> 00:42:20,980
 Det var väl det som hände när jag testade den här tjänsten förut.

491
00:42:20,980 --> 00:42:30,980
 Jag skickade upp på min gammelgammelmormor och så blev det att hon fick någon slags nazistsymboler och så var det en helt annan kvinna.

492
00:42:30,980 --> 00:42:33,980
 Ja, just det. Men jag tycker ändå att den har blivit bättre.

493
00:42:33,980 --> 00:42:35,980
 Ja, verkligen. Det måste jag säga.

494
00:42:36,000 --> 00:42:42,000
 Om vi kollar här, det här är från när mina föräldrar gifte sig.

495
00:42:42,000 --> 00:42:48,960
 Jag tycker ju det där är coolt.

496
00:42:48,960 --> 00:42:49,960
 Det där är coolt.

497
00:42:49,960 --> 00:42:51,960
 För man ser ju att det är en nisse.

498
00:42:51,980 --> 00:42:58,980
 Ja, precis. Han förvandlas ju lite grann till Cornelis Vreeswijk här när han vänder sig om.

499
00:42:58,980 --> 00:43:01,980
 Men jag tyckte också så här, ja det här är ju häftigt.

500
00:43:01,980 --> 00:43:06,980
 Jag har inte skickat det här till min mamma. Jag vågar inte riktigt.

501
00:43:06,980 --> 00:43:14,980
 Och här är en bild på min farfar och min pappa och hans syskon som sitter på en flotte.

502
00:43:15,250 --> 00:43:19,250
 Snackar vi 30-tal?

503
00:43:19,250 --> 00:43:21,250
 Det är Italien någonting.

504
00:43:21,360 --> 00:43:23,360
 Och...

505
00:43:23,539 --> 00:43:30,539
 Det är coolt och vattnet är fantastiskt. Man ser hur det glittrar.

506
00:43:30,539 --> 00:43:32,539
 Så det här var ju coolt.

507
00:43:32,539 --> 00:43:36,539
 Sen så lyckades jag inte hela tiden, utan ibland så funkar det inte.

508
00:43:36,539 --> 00:43:38,539
 Som här till exempel.

509
00:43:38,539 --> 00:43:42,539
 Här blir det bara att den zoomar in fotografiet.

510
00:43:44,119 --> 00:43:51,119
 Så jag vet inte riktigt vad som är kriterierna för att lyckas med det här, om det är någonting med upplösningen eller så.

511
00:43:51,119 --> 00:43:55,119
 Men sen så gick jag vidare här, så jag försökte liksom, man kan ju...

512
00:43:55,420 --> 00:44:03,420
 Det finns en huggning-funktion där man får de två personerna i fotot att kramas.

513
00:44:03,420 --> 00:44:07,420
 Jag har ju sett exempel på det på Instagram och sådär.

514
00:44:08,429 --> 00:44:16,429
 Och det är ju jättefin funktion om man får det att funka, för här är en bild på min pappa och sen en bild på min son och de har aldrig träffats.

515
00:44:16,429 --> 00:44:20,429
 Min pappa dog ju innan min äldste son föddes.

516
00:44:20,429 --> 00:44:27,429
 Och då kan man enligt den här kunna få dem att kramas.

517
00:44:27,429 --> 00:44:36,920
 Jag laddar upp två bilder och sen trycker jag på play.

518
00:44:36,920 --> 00:44:39,920
 En annan man kramar din son, det var inte riktigt det du var ute efter.

519
00:44:39,920 --> 00:44:41,920
 Nej, han kramar inte min son.

520
00:44:41,920 --> 00:44:43,920
 Vi har väl tur, annars hade jag...

521
00:44:43,920 --> 00:44:51,920
 Jag försöker igen med en annan bild, men det går bara inte alls.

522
00:44:51,920 --> 00:44:57,170
 Sen gav jag upp där.

523
00:44:57,170 --> 00:45:05,170
 Men sen fanns det en kyssfunktion, make the two people in the picture kiss.

524
00:45:05,170 --> 00:45:07,170
 Är det där jag på landet?

525
00:45:07,250 --> 00:45:11,250
 Ja, jag laddade upp en bild på dig först och en bild på mig.

526
00:45:11,250 --> 00:45:14,250
 Vad kul att du tog en där och såg så fräsch ut.

527
00:45:14,250 --> 00:45:22,250
 Det var lite svårt att hitta bilder som inte var Heik, så jag ber om ursäkt. Det här var den enda djupskäggbild vi hade på dig.

528
00:45:22,429 --> 00:45:26,429
 Jag antecknar det här.

529
00:45:26,429 --> 00:45:29,429
 Jag hittade en skitsnygg bild på mig.

530
00:45:29,429 --> 00:45:32,429
 som inte alls är AI-genererad heller.

531
00:45:32,429 --> 00:45:36,429
 Okej.

532
00:45:36,429 --> 00:45:45,690
 Jag gillar ändå AIs tolkning av hur jag ser ut.

533
00:45:45,690 --> 00:45:48,690
 Men det här är ju liksom inte bra.

534
00:45:48,690 --> 00:45:50,690
 Det som händer nu...

535
00:45:50,690 --> 00:45:52,690
 Dålig kyss eller?

536
00:45:52,690 --> 00:45:54,690
 Det såg ju väldigt naturligt ut.

537
00:45:54,690 --> 00:46:01,690
 Det som hände nu för er som lyssnar var att det var en bild på Fredrik och bredvid Fredrik var det en bild på mig.

538
00:46:01,690 --> 00:46:11,920
 Och sen så vänder jag mig om och sen så dyker det upp en man i min bild och som jag då kysser.

539
00:46:11,920 --> 00:46:21,920
 Men det måste man ändå säga, rörelsen där du vänder dig, den är bra.

540
00:46:21,920 --> 00:46:25,920
 Det är ju jag. Sådär ser jag ut.

541
00:46:25,920 --> 00:46:33,920
 Jag vill nog inte titta på när jag kysser den här okända mannen något mer. Det är dig som jag har tänkt att vi skulle se.

542
00:46:33,920 --> 00:46:35,920
 Det är mig du vill kyssa.

543
00:46:35,920 --> 00:46:43,920
 Jag tänkte att man skulle kunna ladda upp tjejer där, men det blir lite problematiskt med rörlig bild när man kysser en tjej som inte är sin fru.

544
00:46:44,860 --> 00:46:50,860
 Så jag håller mig till dig och mig.

545
00:46:50,860 --> 00:46:52,860
 på mig så att säga.

546
00:46:52,860 --> 00:46:56,860
 Sådär, nu testar vi igen.

547
00:46:57,389 --> 00:47:01,389
 Men det där är Arnold tycker jag.

548
00:47:02,809 --> 00:47:11,809
 Det där såg inte ut som på exemplen, men det är väldigt...

549
00:47:12,179 --> 00:47:20,179
 Det är ingen scen, eller ingen kyss jag skulle använda i en slutscen i en Hollywoodfilm.

550
00:47:20,179 --> 00:47:30,179
 Men vardagsrealism är det väl, frånsett att vi befinner oss i olika miljöer som vi inte riktigt lyckas gifta ihop.

551
00:47:30,179 --> 00:47:33,179
 Nej, men ändå lyckas litegrann.

552
00:47:33,179 --> 00:47:38,179
 Där gav jag upp kyssexemplet.

553
00:47:38,179 --> 00:47:44,179
 Jag fortsätter här, jag tycker det här var ganska kul.

554
00:47:44,179 --> 00:47:52,579
 Då ska vi se här, två sekunder bara.

555
00:47:52,579 --> 00:47:57,239
 Jag ska bara kolla att min, jag sparkar till min katt där.

556
00:48:01,300 --> 00:48:35,170
 Skit för att jag är djurplågare av mina barn.

557
00:48:35,170 --> 00:48:45,179
 Okej, men sen så fortsätter jag med ninja-versionen av det här, så jag tänkte att min farfar skulle bli ninja.

558
00:48:45,179 --> 00:48:47,179
 Ja, coolt.

559
00:48:47,199 --> 00:48:53,840
 Det ser ut så här.

560
00:48:55,840 --> 00:48:57,840
 Farfar upp i dagen.

561
00:48:57,840 --> 00:49:05,840
 Från att stå vid sin stora trappa där till att bli någon slags Kangfu champion från Japan.

562
00:49:05,840 --> 00:49:13,840
 Sen tog jag en bild från din svensexa för ett antal år sedan.

563
00:49:13,840 --> 00:49:17,840
 Nu är den redan lite omgjord av AI som du ser.

564
00:49:17,840 --> 00:49:21,840
 Och så gjorde jag ninjavarianten av alla som var med på svensexan.

565
00:49:21,840 --> 00:49:27,389
 Ja, det blir inte jättebra.

566
00:49:27,389 --> 00:49:30,389
 Men det är roligt att se folk som slåss.

567
00:49:30,389 --> 00:49:32,389
 Så det var väl kanske ingen topp.

568
00:49:33,650 --> 00:49:37,650
 Och sen slutligen då så har jag en fin bild på dig här.

569
00:49:37,650 --> 00:49:39,650
 Men vad är det därifrån?

570
00:49:39,650 --> 00:49:41,650
 Det är nog från när vi var på...

571
00:49:41,650 --> 00:49:43,650
 Någon konferens?

572
00:49:43,650 --> 00:49:45,650
 Och du har fått en biff.

573
00:49:45,650 --> 00:49:47,650
 Biffor-bea.

574
00:49:47,650 --> 00:49:51,650
 Och så skrev jag att du skulle skratta galet.

575
00:49:51,650 --> 00:49:53,650
 Så vi sätter igång.

576
00:49:53,650 --> 00:50:01,329
 Såg du det eller?

577
00:50:01,329 --> 00:50:04,329
 Nej, den hänger inte riktigt med.

578
00:50:04,329 --> 00:50:07,929
 Nu får ni köra igen.

579
00:50:08,550 --> 00:50:16,460
 Nu ser jag bara en bild på det.

580
00:50:16,460 --> 00:50:20,460
 Ja okej, så jag vet inte om du ser det här.

581
00:50:20,460 --> 00:50:28,460
 Jag ser ungefär och jag har helt andra tänder än vad jag har såklart.

582
00:50:28,460 --> 00:50:33,579
 Du blir en helt annan människa, men det var väl egentligen det.

583
00:50:33,579 --> 00:50:45,579
 Jag tyckte Deep Nostalgia, det är lätt värt om ni vill överraska era föräldrar med någon bild på mormor som är svartvit eller som en ninja.

584
00:50:45,579 --> 00:50:48,579
 Kan ni gå in här?

585
00:50:48,579 --> 00:50:52,579
 Lätt värt tycker jag, 180 spänn att få se de här.

586
00:50:52,579 --> 00:50:56,579
 Det är ju ändå folk som har försvunnit från denna världen.

587
00:50:56,579 --> 00:50:58,579
 Alltså vissa av dem.

588
00:50:58,579 --> 00:51:01,579
 Det känns ju som en sån här tjänst.

589
00:51:01,920 --> 00:51:09,920
 Jag vet inte om jag pratade om det i podden, men ett problem som majoriteten av alla AI-tjänster har är ju churn.

590
00:51:10,030 --> 00:51:18,030
 De har inga problem att få folk som signar upp. Men stannar du månad två i en sån här tjänst, hand om hjärtat?

591
00:51:18,619 --> 00:51:26,619
 Nej, nej, aldrig. Jag har redan sagt upp. Hoppas jag. Så att, ja det hade jag inte. Men nu har jag det.

592
00:51:26,619 --> 00:51:40,150
 Tror du att vi kommer se en skillnad där i framtiden, att man slutar med de här subscription-modellerna och betalar på ett annat sätt?

593
00:51:40,150 --> 00:51:45,150
 Jag tycker alltid man brukar se det, bara ta flygbranschen.

594
00:51:45,150 --> 00:51:50,650
 Kommer du ihåg när SAS inte erbjöd enkelresor?

595
00:51:50,650 --> 00:51:53,150
 Man var tvungen att boka tur och retur.

596
00:51:53,650 --> 00:52:04,650
 Men jag tycker att alla affärsmodeller som inte tänker på kunden i första hand, där det bara är oförståeligt varför man skulle betala, ha det här som en SAS-tjänst.

597
00:52:05,079 --> 00:52:11,079
 Om ett år så vill jag fortfarande ladda upp tio bilder i månaden på gamla släktingar.

598
00:52:11,079 --> 00:52:13,079
 Nej, det funkar inte så.

599
00:52:13,079 --> 00:52:17,079
 Nej, jag tror nog att det kommer ändras, utan tvekan.

600
00:52:17,079 --> 00:52:23,079
 Men du, jag har en till tjänst också. Jag har värsta bonansen den här gången.

601
00:52:23,099 --> 00:52:28,099
 Och det var inne på HayGen för att fixa en grej.

602
00:52:28,099 --> 00:52:33,099
 Som också är en härlig, bra tjänst för att skapa AI-avatarer.

603
00:52:33,239 --> 00:52:42,239
 Och jag brukar ju alltid gå in och titta på Labs. Både HayGen och Eleven Labs har något som heter Labs eller Studio.

604
00:52:42,239 --> 00:52:49,239
 Där man kan hitta deras nya betagrejer som de håller på och testar.

605
00:52:49,239 --> 00:52:58,239
 Och då fanns det, vi har ju testat Interactive Avatar där du träffar en avatar.

606
00:52:58,239 --> 00:53:00,239
 Det var där du träffade Viveca typ?

607
00:53:00,239 --> 00:53:04,239
 Ja, just det. Som ett Zoom-möte.

608
00:53:04,960 --> 00:53:06,960
 Hej Magnus!

609
00:53:07,420 --> 00:53:09,420
 Låt oss prata om det.

610
00:53:09,420 --> 00:53:13,860
 Det var ganska roligt.

611
00:53:13,860 --> 00:53:18,860
 Men då såg jag en ny funktion igår.

612
00:53:18,860 --> 00:53:20,860
 igår.

613
00:53:20,860 --> 00:53:22,860
 Video podcast.

614
00:53:22,860 --> 00:53:24,860
 Video podcast.

615
00:53:24,860 --> 00:53:26,860
 snyggare uttal.

616
00:53:26,860 --> 00:53:28,860
 Och då klickar man på den då.

617
00:53:29,039 --> 00:53:33,039
 Då skickar man in en pdf här bara.

618
00:53:33,150 --> 00:53:39,150
 Så du laddar upp en pdf och sen skapar den en videopodcast utifrån den här pdf:en.

619
00:53:39,150 --> 00:53:43,150
 Så det här är väldigt mycket som Google Notebook LM.

620
00:53:44,000 --> 00:53:46,000
 Som vi har visat.

621
00:53:46,000 --> 00:53:48,000
 Men det här är då med video.

622
00:53:48,000 --> 00:53:50,000
 Ja, vad coolt.

623
00:53:50,000 --> 00:53:52,000
 Jag håller på att skriva en bok.

624
00:53:52,000 --> 00:53:54,000
 Den här boken har jag kommit på vad den ska heta.

625
00:53:54,000 --> 00:53:58,000
 Nu kommer jag inte ihåg riktigt vad jag bestämde.

626
00:53:58,000 --> 00:54:00,000
 Alltså vad var det som hände?

627
00:54:00,000 --> 00:54:02,000
 Alltså vad var det som hände?

628
00:54:02,000 --> 00:54:05,000
 Vad ska du göra utan mig?

629
00:54:05,000 --> 00:54:07,000
 Ja, jag vet inte.

630
00:54:07,000 --> 00:54:15,000
 Så jag laddar upp den boken och sen klickar man på generate video.

631
00:54:15,000 --> 00:54:19,000
 Då får man välja vilken avatar man vill använda sig av.

632
00:54:19,000 --> 00:54:23,000
 Man kan inte använda sin egen än så länge.

633
00:54:23,269 --> 00:54:30,269
 Jag har fixat två video podcasts, en på svenska och en på engelska. Du får höra den på svenska först då.

634
00:54:30,269 --> 00:54:31,269
 Ja, vad kul.

635
00:54:31,349 --> 00:54:34,750
 Härligt. Då kör vi.

636
00:54:36,530 --> 00:54:41,530
 Alltså, har du hört om Magnus Paues och hans oh shit ögonblick? Berätta mer.

637
00:54:41,530 --> 00:54:44,969
 Nej, faktiskt inte. Berätta mer.

638
00:54:44,969 --> 00:54:53,969
 Jo, han satt på sitt kontor i Värmland, hade precis lanserat sin textplattform och så släpper OpenAI Chat GPT. Det vände upp och ner på allt för honom.

639
00:54:53,969 --> 00:54:56,530
 Oj, det måste ha känts som en rejäl kalldusch.

640
00:54:56,530 --> 00:55:03,530
 Ja, verkligen. Men han gav inte upp. Istället han pivotade och integrerade AIN i sin tjänst. Det kräver mod.

641
00:55:03,530 --> 00:55:07,530
 Imponerande. Tvekade han inte. Det måste ha varit en risk.

642
00:55:07,530 --> 00:55:14,329
 Jo, säkert. Men det är som att stå på stranden och se en tsunami komma mot en. Man kan inte ignorera det.

643
00:55:14,329 --> 00:55:17,929
 Nej, sant. Men många är rädda för att AI ska ta deras jobb.

644
00:55:17,929 --> 00:55:24,730
 Absolut, men det är som med alla teknologiska språng. Vi förlorade hästskötare, men fick bilmekaniker.

645
00:55:24,730 --> 00:55:27,250
 Bra poäng. Men tror du alla kan anpassa sig?

646
00:55:27,250 --> 00:55:29,949
 Det är en utmaning, men kanske är det vårt ansvar

647
00:55:29,949 --> 00:55:31,949
 att hjälpa varandra att utvecklas.

648
00:55:31,949 --> 00:55:33,949
 Men kreativiteten då?

649
00:55:33,949 --> 00:55:36,949
 Om AI kan skapa konst och musik, vad finns kvar?

650
00:55:39,010 --> 00:55:49,010
 Jag fattar på vissa grejer, ibland fattar jag inte varför de lägger upp.

651
00:55:49,150 --> 00:55:52,150
 Jag tänkte så här, okej, det här suger verkligen.

652
00:55:52,150 --> 00:56:06,150
 Det är coolt på ett sätt, man ser att de har perfekt läppsynk och så, men svenskan är lite konstig liksom.

653
00:56:06,150 --> 00:56:10,150
 Och kadensen, de har ju verkligen inte lyckats med det som Google har lyckats med i notebook.

654
00:56:10,150 --> 00:56:12,150
 Nej, verkligen inte.

655
00:56:12,150 --> 00:56:18,550
 verkligen låter som en podcast. Det här är inte framme alls, men det är väldigt underhållande.

656
00:56:18,550 --> 00:56:25,550
 Jag tänkte att jag skulle ge Agen en chans till och göra det här på engelska.

657
00:56:25,550 --> 00:56:33,550
 Så jag valde lite andra folk här, men samma fil.

658
00:56:33,550 --> 00:56:34,750
 Vi kör igång.

659
00:56:34,750 --> 00:56:41,250
 So, have you noticed how AI just kind of exploded onto the scene lately?

660
00:56:41,250 --> 00:56:43,809
 It's like we went to sleep and woke up in a new world.

661
00:56:43,809 --> 00:56:45,809
 Absolut, det har varit en lång resa.

662
00:56:45,809 --> 00:56:49,170
 Vad är ditt största borttagande från den här plötsliga förändringen?

663
00:56:49,170 --> 00:56:56,369
 Well, it's like we were working on our own revolutionary platform, and then ChatGPT came along and changed the game entirely.

664
00:56:56,369 --> 00:56:59,170
 Du menar när OpenAI släppte det och skakade branschen?

665
00:56:59,170 --> 00:57:05,170
 Exakt, vi hade precis lanserat vår textplattform och firade och plötsligt insåg vi att vi måste pivotera snabbt.

666
00:57:05,170 --> 00:57:08,449
 Så du bestämde dig för att integrera AI istället för att konkurrera mot det.

667
00:57:08,449 --> 00:57:13,449
 Yes, we did. It's like trying to reinvent the wheel when you could build a better vehicle with the new tech.

668
00:57:13,449 --> 00:57:17,650
 Make sense, do you think people understand how transformative AI will be?

669
00:57:17,650 --> 00:57:19,250
 Helt ärligt, jag är inte säker.

670
00:57:19,250 --> 00:57:24,250
 Only about 29% have used generative AI but soon it will be as common as electricity.

671
00:57:24,329 --> 00:57:27,130
 Det är både fascinerande och lite läskigt.

672
00:57:27,130 --> 00:57:30,329
 Do you think we're maybe normalizing these tech miracles too quickly?

673
00:57:30,329 --> 00:57:35,329
 Exakt. Vi blir förvånade först, men sedan börjar vi nypa minora problem.

674
00:57:37,489 --> 00:57:39,489
 Ja, är du blown away?

675
00:57:40,050 --> 00:57:50,050
 Nej, men som med allt annat så ser man ju, det här är liksom första utkastet, det kommer ju bli otroligt på sikt.

676
00:57:50,449 --> 00:57:56,449
 Absolut. Var det inte lite kul att den killen började prata mer indisk direkt?

677
00:57:56,449 --> 00:58:00,449
 Jag tyckte han var behaglig på ett obehagligt sätt.

678
00:58:00,449 --> 00:58:03,449
 Är det på ett lobotomerat sätt?

679
00:58:03,449 --> 00:58:16,449
 Du vet någon som har jobbat som managementkonsult och sen går i kloster i 12 år och sen kommer tillbaka och föreläser om det. Den känslan.

680
00:58:16,449 --> 00:58:23,449
 Jag vill berätta om vad som hände i kändisskapet.

681
00:58:23,449 --> 00:58:28,329
 Men det där tyckte jag ändå rörde om i grytan.

682
00:58:28,369 --> 00:58:29,409
 Det var kul.

683
00:58:29,409 --> 00:58:31,409
 Ja, vad kul.

684
00:58:31,409 --> 00:58:41,409
 Och svenskan kom ju alltid lite på efterkälken, men det var ju underhållande om inte annat, så jag skrattade högt även när jag gjorde det här själv.

685
00:58:41,409 --> 00:58:42,909
 Det kan jag tipsa om.

686
00:58:42,909 --> 00:58:44,909
 Gå in på hagen.

687
00:58:44,909 --> 00:58:52,909
 Jag tror inte ens man behöver ha någon subscription, utan man kan göra det här själv. Så det är bara att gå in och göra.

688
00:58:52,909 --> 00:58:58,030
 Så att, ja, men det var det som jag hade. Har du något mer, Fredrik?

689
00:58:58,030 --> 00:59:04,030
 Nej, jag tror inte det. Jag tar nya taget nästa vecka och ska försöka bli blown away då istället.

690
00:59:04,429 --> 00:59:06,429
 Ja, men det låter bra.

691
00:59:06,429 --> 00:59:09,190
 Jag vill slå ett slag för våra AI-föreläsningar.

692
00:59:09,190 --> 00:59:14,909
 Hör av er om ni är intresserade av att vi kommer att köra en inspirationsföreläsning på en eller tre timmar.

693
00:59:14,909 --> 00:59:18,110
 Vi gör också sådana här AI-assistenter, så hör av er.

694
00:59:18,110 --> 00:59:21,469
 Gå in på veckans.ai om ni vill ha kontaktuppgifter.

695
00:59:21,469 --> 00:59:25,469
 Annars så säger vi ha det bra.

696
00:59:25,469 --> 00:59:26,469
 Gud vad svårt.

697
00:59:26,469 --> 00:59:28,469
 Ha det bra. Vi ses nästa vecka. Hej.

