1
00:00:00,530 --> 00:00:02,529
 Så att du ska slippa.

2
00:00:02,529 --> 00:00:04,530
 Hur är läget med dig, Fredrik?

3
00:00:04,580 --> 00:00:14,080
 Jag mår bra, jag är lite sur på AI för tillfället men livet i övrigt är fantastiskt!

4
00:00:14,160 --> 00:00:20,820
 Härligt! Man blir lite nyfiken på att du blir sur på AI som om det vore

5
00:00:20,820 --> 00:00:23,920
 en fru eller något sådant.

6
00:00:23,920 --> 00:00:27,120
 Jag grälar inte med AI om ekonomi.

7
00:00:30,000 --> 00:00:37,000
 Nej, men det är intressant när man gör den här podden, så är det oftast väldigt kul

8
00:00:37,000 --> 00:00:42,500
 att sitta och testa olika tjänster och oftast landar det faktiskt i att man blir imponerad

9
00:00:42,609 --> 00:00:50,009
 Men just den här veckan har jag haft svårt att komma överens med de tjänster jag har testat.

10
00:01:00,000 --> 00:01:09,200
 och det är lite av vilda västern där ute med företag som bygger AI-tjänster.

11
00:01:09,200 --> 00:01:15,120
 Det verkar inte alltid krävas jättemycket kompetens för att kasta upp något på nätet

12
00:01:15,120 --> 00:01:17,120
 som man tar betalt för.

13
00:01:30,000 --> 00:01:38,000
 Jag fattar. Vi hör ju till en väldigt ovanlig del av AI-nyttjarna.

14
00:01:38,000 --> 00:01:40,159
 Alltså de som poppar på allt.

15
00:01:40,159 --> 00:01:44,280
 på alla AI-tjänster som jag testar och försöker komma ihåg

16
00:01:44,439 --> 00:01:46,319
 och stänga av subscription och så där.

17
00:01:46,319 --> 00:01:49,640
 men vi får ta in en konsult och göra en översyn.

18
00:01:49,640 --> 00:01:51,879
 Jag är ganska säker på att båda våra datorer har någon slags

19
00:01:51,879 --> 00:01:55,120
 digital variant av ebola, minst.

20
00:01:55,120 --> 00:01:56,680
 Troligtvis.

21
00:01:56,680 --> 00:01:58,680
 Har du några nyheter idag?

22
00:01:58,950 --> 00:02:03,549
 Ja, ett sorgligt besked för vissa, kanske.

23
00:02:03,549 --> 00:02:12,550
 Det är att det här företaget Humane, som gjorde AI-pinnen som kom förra våren, tror jag.

24
00:02:12,550 --> 00:02:17,550
 De kastade in handduken och säljer sina kvarvarande tillgångar till HP.

25
00:02:17,759 --> 00:02:23,259
 Just det, en AI-pinn som man sätter på kroppen och så lyssnar på allt man säger och ser allt man ser.

26
00:02:30,000 --> 00:02:35,580
 Exakt, och jag tror att tanken, eller marknadsföringen har gått ut lite på att man

27
00:02:35,599 --> 00:02:41,960
 ska göra sig kvitt sitt skärmberoende och så ska man få den här fina AI-hjälpen ändå.

28
00:02:42,000 --> 00:02:47,479
 Det kanske var så att världen inte var mogen för det och att det kommer,

29
00:03:00,000 --> 00:03:09,000
 Mättade av väldiga problem. Dels var nålen svindyr. Den kostade 7-8 000 kronor.

30
00:03:09,159 --> 00:03:10,360
 För en nål bara liksom?

31
00:03:10,520 --> 00:03:16,219
 Ja, exakt. Och det är så här att den löser problem som du faktiskt bara kan lösa genom att

32
00:03:16,219 --> 00:03:21,539
 Jag kan ha en uppskattning för att folk försöker.

33
00:03:21,539 --> 00:03:27,819
 Jag tror att det var Oricles vd och grundare, Douglas Elements, som sa:

34
00:03:27,979 --> 00:03:33,620
 Om du inte skäms för din första lansering, eller produkt i efterhand

35
00:03:33,620 --> 00:03:36,620
 då har du väntat för länge med att lansera den.

36
00:03:36,620 --> 00:03:41,620
 Det är väl det vi ser också, att det är helt sjuka grejer som släpps där.

37
00:03:41,620 --> 00:03:43,659
 Det är bara att åka med.

38
00:03:43,740 --> 00:03:46,659
 Ja, verkligen. Nu kommer jag att tänka på voddler. Kommer du ihåg voddler?

39
00:03:46,740 --> 00:03:50,300
 Ja. Det var väl en föreläsning till Netflix?

40
00:04:00,000 --> 00:04:09,039
 Ja, exakt. En tjänst som var jättebra i det, streama video, men tyvärr, ni var lite tidiga för att folk fortfarande hade 28/8 modem.

41
00:04:09,039 --> 00:04:13,120
 Det var ganska jobbigt, men då hade jag faktiskt voddler som sällskap.

42
00:04:13,120 --> 00:04:15,740
 och jag tyckte tjänsten funkade helt klockrent.

43
00:04:15,740 --> 00:04:21,420
 Man hade glömt den här detaljen, att man måste ha bra filmer i sitt utbud.

44
00:04:21,920 --> 00:04:23,279
 Okej, men det var det.

45
00:04:23,279 --> 00:04:29,959
 Men jag kommer ihåg att jag fick en förhands-invite till voddler och tänkte att det här

46
00:04:29,959 --> 00:04:34,160
 kommer bli grymt. Men jag hade alldeles för dålig uppkoppling.

47
00:04:34,160 --> 00:04:39,279
 Den var lite tidig, men den var bra. Och sen var det ett jättefult namn.

48
00:04:39,279 --> 00:04:42,600
 Okej, Netflix gick ju... Det gick ju bra för dem.

49
00:04:42,600 --> 00:04:49,000
 Så vi kommer inte köpa någon human-pin, AI-pin.

50
00:04:49,000 --> 00:04:52,639
 Vi kommer väl kanske köpa ett par Meta sådana här Reben wearables?

51
00:04:52,660 --> 00:04:55,480
 Absolut, den är ju väldigt populär.

52
00:05:00,000 --> 00:05:05,360
 Ja, det kan jag uppskatta ändå, tänket i det.

53
00:05:05,519 --> 00:05:08,720
 Reaban, skitsnygga glasögon.

54
00:05:08,879 --> 00:05:14,279
 Att man utgår från vad folk vill ha på sig snarare än vad som går att göra.

55
00:05:14,279 --> 00:05:19,560
 försöker gå den vägen. Nu vet jag att Zuckerberg har den där prototypen som kostar

56
00:05:19,560 --> 00:05:22,680
 hundratusen kronor att tillverka.

57
00:05:22,680 --> 00:05:25,579
 Så den kommer vi inte få se, men att man börjar i den änden.

58
00:05:25,579 --> 00:05:27,720
 Vad vill folk ha på sig?

59
00:05:27,720 --> 00:05:33,480
 Och så ser vi hur mycket teknik vi kan få in i det snarare än att vi gör asfula grejer.

60
00:05:33,480 --> 00:05:36,360
 Det är nog rätt smart.

61
00:05:36,379 --> 00:05:37,899
 Bra tänkt!

62
00:05:37,920 --> 00:05:39,620
 Mycket bra!

63
00:05:39,639 --> 00:05:41,860
 Ja, men grymt!

64
00:05:41,860 --> 00:05:46,120
 Då kanske vi väntar med humains AIP.

65
00:05:46,139 --> 00:05:47,500
 Det var ju bra att vi inte köpte en sån.

66
00:05:47,500 --> 00:05:50,939
 Ni som har den kommer sluta fungera den 28 februari.

67
00:05:50,959 --> 00:05:54,259
 Så njut den här sista veckan.

68
00:05:54,259 --> 00:05:57,579
 Det stod att vissa funktioner kommer att fungera,

69
00:05:57,579 --> 00:06:01,660
 typ att den berättar om batteriet på väg att börja ta slut.

70
00:06:01,709 --> 00:06:06,829
 Berätta om batteriet på väg att börja brinna, som också har varit ett fall.

71
00:06:06,829 --> 00:06:11,110
 Ja, just det. Det är värt 7000, bara det.

72
00:06:11,110 --> 00:06:13,110
 Att ha en sådan produkt.

73
00:06:13,110 --> 00:06:15,110
 Like säger vi.

74
00:06:15,110 --> 00:06:17,110
 Ja, verkligen. Kul!

75
00:06:17,110 --> 00:06:19,110
 Min nyhet är

76
00:06:30,000 --> 00:06:37,000
 Grock 3 har släppts. Alltså, det... Träskmonstret GROCK.

77
00:06:37,000 --> 00:06:43,000
 OpenAI-modellerna. Det står här på någon sida som jag varit inne på

78
00:06:43,079 --> 00:06:44,100
 på Mashable.

79
00:06:44,100 --> 00:06:48,300
 GRUC 3 är lika bra som sina privilegier, men inte tillräckligt bra för att

80
00:06:48,300 --> 00:06:53,860
 Make a cancel your chat GPT subscription.

81
00:06:53,860 --> 00:06:56,180
 Så att, ja... Spännande.

82
00:07:00,000 --> 00:07:06,000
 Jag låter kanske lite trött när jag pratar om det här.

83
00:07:30,000 --> 00:07:43,500
 Nu finns det ju rätt många jättevälfinansierade stortech-bolag som håller på och kämpar med sina frontier model, som de kallas.

84
00:07:43,500 --> 00:07:46,860
 Enthropic, det tar aldrig slut.

85
00:07:46,860 --> 00:07:53,060
 En reflektion där också är att det är intressant att...

86
00:08:00,000 --> 00:08:01,779
 Det känns som att de mäter den här

87
00:08:03,579 --> 00:08:07,420
 olika L &amp; Lemsens intelligens

88
00:08:07,420 --> 00:08:11,000
 genom hur svåra och komplexa mattetal de kan lösa.

89
00:08:11,000 --> 00:08:14,000
 resoning capabilities.

90
00:08:14,000 --> 00:08:17,000
 Men det är också intressant hur

91
00:08:17,000 --> 00:08:19,439
 hur platt det kan falla om man...

92
00:08:19,600 --> 00:08:22,680
 Den har jättesvårt till exempel att tolka bilder.

93
00:08:30,000 --> 00:08:36,360
 Jag skulle göra en logga häromdagen med text i och då bara...

94
00:08:36,360 --> 00:08:44,960
 Den är helt värdelös på att stava rätt och sånt i bilder.

95
00:08:44,960 --> 00:08:48,679
 Där tänker jag att man missar målet ganska mycket genom att...

96
00:09:00,000 --> 00:09:05,120
 Det där är rätt intressant, för det finns ju tjänster som...

97
00:09:05,120 --> 00:09:11,000
 Det finns ju bara en bildgenereringstjänst som klarar av text.

98
00:09:11,000 --> 00:09:13,000
 Att generera text.

99
00:09:13,000 --> 00:09:17,000
 Och det är... Kommer du ihåg, eller?

100
00:09:17,000 --> 00:09:21,000
 på ett sätt, det också på något sätt.

101
00:09:30,000 --> 00:09:38,000
 Ideogram heter den. Den genererar ju, det är text till bildgenerator som fixar text också.

102
00:09:38,000 --> 00:09:41,519
 karaktär under en längre period.

103
00:09:42,879 --> 00:09:45,919
 Och det är rätt kul, för att de här två grejerna,

104
00:09:46,000 --> 00:09:50,000
 att generera text i bild och det här med karaktärer,

105
00:10:00,340 --> 00:10:07,960
 Det fixar ju inte de här frontier models. Jag använder ju klåd jättemycket för att skriva och sådär.

106
00:10:08,200 --> 00:10:11,440
 Jag laddar upp texter och sådär.

107
00:10:11,440 --> 00:10:16,399
 Och den håller den i ett tag, men sen glömmer den bort det.

108
00:10:16,480 --> 00:10:19,299
 Som man märker, det smyger sig på.

109
00:10:19,299 --> 00:10:22,240
 Vänta nu, nu tycker jag inte att du har den där toniditeten som jag bad om.

110
00:10:22,240 --> 00:10:23,740
 Den är som människor i allmänhet?

111
00:10:30,370 --> 00:10:38,370
 I processen så har den släppt den här karaktären då. Eller tonaliteten.

112
00:10:38,370 --> 00:10:43,370
 Och då tänker jag bara såhär: Ska de lägga lite krut på att bara fixa de här grejerna?

113
00:10:43,370 --> 00:10:45,370
 Eftersom det uppenbarligen går att fixa.

114
00:11:00,000 --> 00:11:04,360
 Det är väldigt intressant, vi som bara skrapar på ytan av AI

115
00:11:04,360 --> 00:11:08,759
 och inte alls kan så mycket om själva den grundläggande tekniken.

116
00:11:08,759 --> 00:11:15,519
 Men också det här exemplet vi har sett när vi har testat fel antal fingrar och sånt.

117
00:11:15,519 --> 00:11:20,879
 Man tycker att det borde vara en jätteenkel sak för dem att ställa in.

118
00:11:20,879 --> 00:11:27,519
 nya modeller. Jag fattar det, för de har ju ett mål och det är AGI, alltså artificiell generell intelligens.

119
00:11:28,049 --> 00:11:31,049
 Och den som kommer fram dit först vinner, typ.

120
00:11:31,049 --> 00:11:37,889
 Men på vägen så vore det ju kul om de inte skulle glömma oss vanliga konsumenter

121
00:11:37,889 --> 00:11:42,809
 som vill generera fram människor med fem fingrar.

122
00:11:42,970 --> 00:11:44,970
 Bara ge oss det, så är vi glada sen.

123
00:12:00,000 --> 00:12:03,000
 Med tryck på t-shirten.

124
00:12:03,000 --> 00:12:06,000
 Ja, det var väl nyheterna.

125
00:12:06,000 --> 00:12:09,000
 Nu har vi bashat av storbolagen.

126
00:12:09,000 --> 00:12:12,000
 Exakt. Allt vad de heter.

127
00:12:12,000 --> 00:12:15,000
 De kan...

128
00:12:15,000 --> 00:12:17,000
 De kan få bättre sig.

129
00:12:17,000 --> 00:12:19,000
 Jag vågar inte säga någonting.

130
00:12:30,000 --> 00:12:36,820
 det, och jag nämnde det tidigare också, när man testar massa tjänster så har

131
00:12:36,820 --> 00:12:42,320
 högre makt, ungefär som Apple eller OpenAI.

132
00:13:00,000 --> 00:13:08,240
 För det är så fruktansvärt lätt att skapa en AI-tjänst och stoppa ut den där ute.

133
00:13:08,399 --> 00:13:14,399
 Det vore bra med en expert-rating-sajt.

134
00:13:14,509 --> 00:13:18,269
 Apropå det, varför ska inte vi skapa en sån sida?

135
00:13:18,269 --> 00:13:20,710
 Det är väl precis i linje med den här podden.

136
00:13:20,710 --> 00:13:23,710
 Jag tänker så här, vi ska göra det,

137
00:13:23,710 --> 00:13:27,669
 men vi ska göra det på ett sätt som inte tar en massa tid.

138
00:13:30,000 --> 00:13:33,899
 Så jag tänker att om vi gör någon bott som

139
00:13:34,019 --> 00:13:39,179
 crawlar alla våra avsnitt och skapar...

140
00:13:39,200 --> 00:13:41,139
 Det där borde man väl kunna fixa i Love Dire?

141
00:13:41,139 --> 00:13:47,139
 Som inte är alltför tekniskt utmanande att göra.

142
00:13:47,139 --> 00:13:49,919
 Så vi kan skriva upp den på vår to-do-lista.

143
00:13:49,919 --> 00:13:52,639
 Men bra, innan du...

144
00:13:52,639 --> 00:13:55,240
 Eller om det är en skittjänst,

145
00:13:55,259 --> 00:14:00,120
 ska vi kanske skita i att visa den så kan du förklara vad du har upplevt istället?

146
00:14:00,139 --> 00:14:02,419
 Nej, jag tycker jag ska visa den.

147
00:14:02,440 --> 00:14:03,399
 Du ska visa skittjänsten?

148
00:14:03,399 --> 00:14:05,639
 Ja, annars förstår man inte.

149
00:14:05,720 --> 00:14:09,679
 Vi måste vara tydliga med vad som är skit.

150
00:14:09,679 --> 00:14:11,679
 Nu börjar vi bli lite lättade.

151
00:14:11,679 --> 00:14:14,679
 Jag tänkte på det när du testade det här.

152
00:14:14,679 --> 00:14:19,080
 Man vill ju någonstans att alla tjänster ska lyckas, som vi testar.

153
00:14:19,080 --> 00:14:24,759
 Men vi testar tjänster, det är inte så att vi säger att nu ska vi få alla tjänster att lyckas.

154
00:14:24,759 --> 00:14:27,000
 Full these closure.

155
00:14:27,000 --> 00:14:27,720
 Exakt.

156
00:14:30,019 --> 00:14:39,019
 Innan du gör det, jag är väldigt nyfiken på hur din AI-index har gått, din daytrading.

157
00:14:39,019 --> 00:14:43,019
 Kan vi prata lite mer om den? - Nej, nej, men det är...

158
00:14:43,019 --> 00:14:45,500
 När har du förlorat? Jag ligger 200 kronor back.

159
00:14:45,500 --> 00:14:51,820
 Det mesta av det är för att min courtage-klass...

160
00:15:00,000 --> 00:15:03,399
 Visa att man betalar för att köpa och sälja aktier.

161
00:15:03,480 --> 00:15:08,360
 Den är för dyr för de små belopp jag tjänar.

162
00:15:08,440 --> 00:15:11,240
 Jag är inne på att byta strategi.

163
00:15:30,000 --> 00:15:32,000
 Satte du in?

164
00:15:32,000 --> 00:15:34,000
 10 000.

165
00:15:34,000 --> 00:15:36,000
 Ja, men det var ändå 10 000.

166
00:15:36,000 --> 00:15:40,000
 Jag tyckte att det låter som en...

167
00:15:40,000 --> 00:15:44,000
 Du borde kunna starta på 10 000 och göra din förmögenhet.

168
00:15:44,000 --> 00:15:46,200
 i förlust... Ja, men exakt.

169
00:15:46,200 --> 00:15:52,000
 Så den måste vara uppe på en bra bit över 1 % för att den ska kännas värd att göra.

170
00:16:00,000 --> 00:16:06,360
 Sen till AI:s försvar kan jag säga att de aktier jag köpt har på det stora hela gått upp

171
00:16:06,519 --> 00:16:11,720
 men inte på den nivån att det har varit lönsamt än.

172
00:16:11,720 --> 00:16:16,840
 Det här kan jag ändra. Jag skulle kunna fixa så att jag har en...

173
00:16:16,840 --> 00:16:21,240
 Vi ska inte fastna i en courtage-diskussion, men det kan vi ställa in också.

174
00:16:30,000 --> 00:16:38,879
 Men du har alltså betalat 7 dagar gånger 70 spänn? 490 spänn i courtage?

175
00:16:38,879 --> 00:16:44,679
 Det är enkelt att fixa, men sen drabbar det min övriga portfölj.

176
00:16:44,679 --> 00:16:49,679
 Jag har inte gett upp. Jag tror att jag måste finkalibrera och tänka till lite.

177
00:16:49,679 --> 00:16:54,779
 Okej, ja men bra. Förlåt att jag frågade, men jag tror att det är många som...

178
00:16:54,779 --> 00:16:59,000
 Det var jättebra att det följde upp. Många där ute som har höga förhoppningar.

179
00:16:59,000 --> 00:17:01,360
 Apropå full Disclosure.

180
00:17:01,360 --> 00:17:05,039
 Okej, visa din dåliga AI-tjänst!

181
00:17:05,039 --> 00:17:09,640
 Men ja, jag kan börja med att berätta vad det är för tjänst.

182
00:17:09,799 --> 00:17:13,799
 Det är för folk som är väldigt stressade.

183
00:17:13,960 --> 00:17:18,359
 De har många grejer som ligger varje dag som de måste ta tag i.

184
00:17:18,359 --> 00:17:23,619
 Kan du känna igen dig i det här, Magnus? Att det var ett stort moln av skit du måste göra?

185
00:17:23,619 --> 00:17:27,220
 Ja, lite så.

186
00:17:30,000 --> 00:17:32,400
 Just nu har jag haft en sådan period faktiskt.

187
00:17:32,480 --> 00:17:36,160
 Jag brukar vara rätt duktig på yin och yang.

188
00:17:36,240 --> 00:17:38,640
 Men jag har haft sjuka barn.

189
00:17:38,640 --> 00:17:43,119
 planerar lite grann, men jag kan ändå fatta.

190
00:17:43,119 --> 00:17:51,079
 Ja, den tjänst som jag har testat heter alltså before sunset.

191
00:17:51,079 --> 00:17:56,339
 Vad jag markerar så du kan sätta igång i lugn och ro.

192
00:17:56,380 --> 00:17:58,059
 Hur är det för att få ljud?

193
00:17:58,099 --> 00:18:00,500
 Är det bara flik man kan dela, eller hur?

194
00:18:00,500 --> 00:18:06,799
 Var noga med att bara beskriva det du ser.

195
00:18:06,799 --> 00:18:14,500
 Ja, det vi ser nu när jag delar med skärm här är ett flöde där man kan skapa

196
00:18:14,500 --> 00:18:20,259
 alltså att göra-listor, och då är det uppdelat i arbete och personliga saker.

197
00:18:30,000 --> 00:18:36,140
 För det här exemplet har jag lagt in några arbets-to-does.

198
00:18:36,400 --> 00:18:42,539
 Det är att spela in podcast, skriva lite cockpit till en kund, och lära mig mer om Anything Ella Lem,

199
00:18:42,539 --> 00:18:49,660
 Personliga saker. Jag och Magnus har åkt till fjällen, så jag ska förbereda en handlingslista.

200
00:19:00,000 --> 00:19:07,000
 Jag ska hjälpa ungarna med läxor och laga mat och så ska jag träna. Det är det jag ska hinna med idag är tanken.

201
00:19:07,430 --> 00:19:20,410
 Okej, så då kan jag bland annat då Plan my day klicka på den och då får jag en sån här Time management mumbo jumbo.

202
00:19:30,000 --> 00:19:34,000
 Det finns olika metoder för hur man kan planera sin dag.

203
00:19:34,000 --> 00:19:41,000
 IT FROG, att man tar den svåraste uppgiften först.

204
00:19:41,000 --> 00:19:44,000
 Vilken hemsk analogi!

205
00:19:44,000 --> 00:19:49,759
 ihop liknande uppgifter och sedan TaskRide, Switch between different tasks.

206
00:19:49,759 --> 00:19:52,980
 Jag kan ta Batch Simbler och klicka på den.

207
00:20:00,559 --> 00:20:02,559
 Då ser vi att AI:n jobbar här.

208
00:20:02,559 --> 00:20:05,559
 Vilken trevlig liten animering som kom där.

209
00:20:05,559 --> 00:20:08,559
 Det sprätte iväg någonting.

210
00:20:08,559 --> 00:20:13,559
 Då ser vi att AI:n har tagit sig friheten att planera exakt i vilken ordning

211
00:20:13,559 --> 00:20:15,319
 Alltså en sorteringsapp.

212
00:20:15,319 --> 00:20:21,059
 Den sorterar dina to-dos på ett sätt som är lite oklart.

213
00:20:21,059 --> 00:20:25,180
 Bland annat, gissar jag.

214
00:20:30,000 --> 00:20:36,000
 Sen ska jag visa en annan AI-funktion. Nu har jag...

215
00:20:36,000 --> 00:20:39,720
 Man ser här att det är planerat att det tar en halvtimme och sedan ska

216
00:20:39,720 --> 00:20:43,319
 jag markera hur lång tid det tar och så kan jag starta tiden när jag börjar.

217
00:20:43,559 --> 00:20:54,559
 Men sen då om jag vill använda AI även här, då ska jag klippa AI-assistenten och klicka på Create Subtask.

218
00:21:00,000 --> 00:21:05,000
 Då styckar den upp den här To-Do-listan i flera videos.

219
00:21:05,000 --> 00:21:10,000
 Äter elefanten i små delar. I IT-frog-tanken här.

220
00:21:30,000 --> 00:21:46,279
 Jag fattar! Det är väl inte så dumt. Jag tänker såhär, prokrastrinering, att skjuta saker på framtiden, det är vi bäst på vi människor.

221
00:21:46,279 --> 00:21:54,279
 En till uppgift i sig som tar tid och fokus från det man egentligen ska göra.

222
00:21:54,279 --> 00:21:57,920
 Du tror inte riktigt på själva grundidén här hör jag?

223
00:21:57,920 --> 00:22:01,920
 Nej. Sen är ju livet sällan så här.

224
00:22:01,920 --> 00:22:06,400
 Sen vet jag att man kan ju koppla den här mot sin egen kalender, och så vidare.

225
00:22:06,400 --> 00:22:15,240
 så fasta inbokningar i kalendern, då fattade den att den ska planera runt om.

226
00:22:15,400 --> 00:22:21,319
 Men sen ska jag visa en sista funktion som jag tyckte var lite rolig.

227
00:22:21,480 --> 00:22:24,160
 ”Focus with Oasis.” Klicker på den.

228
00:22:24,160 --> 00:22:25,759
 Vad är det då?

229
00:22:25,759 --> 00:22:33,599
 Då kommer jag istället för att se hela flödet och blir alldeles stressad, så kan jag få bara den här checklistan med bakgrund

230
00:22:33,599 --> 00:22:36,599
 som är en vacker stuga.

231
00:22:36,599 --> 00:22:38,599
 En genererad bild, säkert.

232
00:22:38,599 --> 00:22:42,599
 Och sen har jag ett litet inspirationscitat här.

233
00:22:42,599 --> 00:22:45,160
 I have everything I need within me to succeed.

234
00:22:45,160 --> 00:22:48,160
 Så det är en digital fortune cookie som dyker upp här.

235
00:22:48,160 --> 00:22:51,160
 Och det här är också viktigt.

236
00:23:00,000 --> 00:23:08,000
 Att jag kan få lite meditationsmusik medan jag bockar av min lista.

237
00:23:12,000 --> 00:23:16,000
 Skulle man kunna säga... Och du har Fireplay sound också.

238
00:23:16,000 --> 00:23:22,960
 att man behöver den här appen, då är troligtvis inte appen lösningen på det här.

239
00:23:30,240 --> 00:23:36,039
 Ditt liv är väl det som är rådet?

240
00:23:36,200 --> 00:23:40,759
 Om man ska dela in tjänster i "nice to have" och "neat to have"

241
00:23:40,759 --> 00:23:42,759
 Här som sagt.

242
00:23:42,759 --> 00:23:44,500
 Jag tänkte ju säga det, en tredje kategori här.

243
00:23:44,500 --> 00:23:45,680
 Not nice.

244
00:23:45,680 --> 00:23:49,480
 Jag tycker det här verkar sortera in där.

245
00:23:49,480 --> 00:23:56,440
 Ja, och nu ska vi inte trampa stressade folk på tårna som verkligen går igång på det här.

246
00:23:56,440 --> 00:24:02,599
 "'Ja, det här behöver jag', men om det är nån som gillar det här, gå in och skaffa tjänsten

247
00:24:02,599 --> 00:24:07,720
 och så återkopplar ni till mig sen, om det har ändrat ert liv.

248
00:24:07,720 --> 00:24:11,319
 Men that's it for me, ungefär.

249
00:24:11,319 --> 00:24:17,319
 Jag tyckte att det var en snygg UX-bild på den här sidan.

250
00:24:17,319 --> 00:24:22,319
 De hade en bra yrkesdesign, så det tyckte jag var positivt.

251
00:24:22,319 --> 00:24:26,759
 Bra! Lyckades du avsluta abonnemanget?

252
00:24:26,920 --> 00:24:28,680
 Det ska jag göra nu.

253
00:24:30,000 --> 00:24:33,460
 Det har ändå kostat mig 120 kronor.

254
00:24:33,480 --> 00:24:38,700
 Ja, okej. Härligt!

255
00:24:38,700 --> 00:24:40,700
 Det kan du fixa din mick.

256
00:24:40,809 --> 00:24:54,480
 Jag har lite olika grejer här den här dagen.

257
00:25:00,750 --> 00:25:08,750
 För det första så tänkte jag, jag kom på det, jag förberedde en föreläsning för ett gäng som jag ska hålla.

258
00:25:08,750 --> 00:25:13,750
 och kom på att jag kan rätt mycket om hur det funkar.

259
00:25:13,750 --> 00:25:20,390
 Och jag vet vissa tricks som kanske inte alla vet.

260
00:25:20,390 --> 00:25:26,109
 Så jag tänkte börja med, eftersom vi har så många lyssnare nu för tiden, och alla är väl på olika nivå.

261
00:25:26,109 --> 00:25:31,150
 men jag tänkte i alla fall dela med mig av fem snabba om ChatGPT, till att börja med.

262
00:25:31,150 --> 00:25:36,269
 Och sen tänkte jag gå in på mina ganska roliga tjänster.

263
00:26:31,579 --> 00:26:41,380
 Okej, den första grejen som jag har, det är egentligen att du kan...

264
00:26:41,380 --> 00:26:48,380
 ChatGPT kan skapa Excel och PowerPoint. Alltså filerna.

265
00:26:48,380 --> 00:26:54,579
 Ofta kan ChatGPT skapa det mesta, spara i Word eller PDF.

266
00:26:54,579 --> 00:26:57,980
 Så det är en ganska bra grej att känna till.

267
00:26:57,980 --> 00:27:01,579
 Blir det bra också?

268
00:27:01,579 --> 00:27:03,579
 Speaker Notes.

269
00:27:04,650 --> 00:27:08,930
 Och sen bad jag den: Få in bilderna i en PowerPoint!

270
00:27:09,089 --> 00:27:12,049
 Och då, som du ser här, så sa den:

271
00:27:12,049 --> 00:27:16,089
 ”Jag har skapat en Powerpoint-presentation om vad grejer du kan ladda ner här”.

272
00:27:16,089 --> 00:27:20,630
 Och då gjorde jag det. Och då blev det så här.

273
00:27:20,630 --> 00:27:22,230
 Wow.

274
00:27:30,720 --> 00:27:41,480
 Så det blev en PowerPoint-presentation, men det är fortfarande så att man får göra resten själv.

275
00:27:41,480 --> 00:27:45,079
 Ja precis, men fördelen med det här, om man nu ser det positivt,

276
00:27:45,079 --> 00:27:53,160
 Så då är det ju att du får in de här sliderna, du kanske har skapat 30 slides och då får du in all information på sliderna.

277
00:28:00,000 --> 00:28:09,920
 Sen kan du typ i Canva, som är min favorittjänst för att skapa presentationer, eller Powerpoint om du vill jobba med det.

278
00:28:09,920 --> 00:28:14,720
 Så då kan man gå in och göra om de här på olika sätt.

279
00:28:14,720 --> 00:28:20,720
 Den är inte jättebra kan jag säga.

280
00:28:20,720 --> 00:28:27,720
 Den vill jag inte presentera här. Det var en grej.

281
00:28:30,180 --> 00:28:38,180
 Sen som du såg, se det här, så bad jag den skapa en bild som inspireras av detta i renässansstil.

282
00:28:38,180 --> 00:28:46,180
 Och jag tycker inte Dal är, alltså ChatGPT:s bildgenereringsfunktion är speciellt bra.

283
00:29:00,000 --> 00:29:09,000
 Det här är ju, ja, jag vet inte. Men tricket som jag, för det är många som använder sig av, det ser man på LinkedIn om inte annat,

284
00:29:09,000 --> 00:29:12,720
 klickar på den då kommer den upp i ett litet annat läge och

285
00:29:12,720 --> 00:29:17,180
 då finns det en liten en liten ikon som ser ut som en

286
00:29:17,180 --> 00:29:23,579
 pensel med en pil runt och väljer man den då kan man faktiskt gå in och

287
00:29:23,579 --> 00:29:28,279
 prompta om bara en liten grej.

288
00:29:30,000 --> 00:29:36,599
 Så jag vill byta ut den här mot en groda.

289
00:29:36,759 --> 00:29:42,039
 Byt ut denna mot en groda, skriver jag.

290
00:29:42,039 --> 00:29:50,039
 Ja exakt, exakt. Sen så tror jag eventuellt att Photoshops är lite bättre.

291
00:29:50,039 --> 00:29:53,039
 Men då ska vi se.

292
00:30:01,779 --> 00:30:09,329
 Och ja, den jobbar eller vad händer?

293
00:30:10,819 --> 00:30:24,710
 Och då jobbar den här och nu ska de byta ut roboten mot en groda, och det gjorde den som du ser.

294
00:30:30,019 --> 00:30:32,579
 Men den har försökt ha hela bilden.

295
00:30:32,579 --> 00:30:39,259
 Det har den ju för sig gjort, men nu tänkte jag försvara

296
00:30:39,259 --> 00:30:46,220
 Nu får de skämmas. Men den funkar ibland, säkert hälften av gångerna.

297
00:30:46,220 --> 00:30:48,819
 Den finns där i alla fall.

298
00:31:00,000 --> 00:31:06,140
 På tal om att hålla karaktär i en längre tid.

299
00:31:07,680 --> 00:31:08,700
 Ja, exakt.

300
00:31:08,700 --> 00:31:11,700
 med ChatGPT ibland för att det ska bli som man vill.

301
00:31:30,720 --> 00:31:37,160
 Men där kan man göra, ni får testa själva.

302
00:31:37,160 --> 00:31:42,000
 De hatar den. Alltså jag hatar den också. Varför ska jag behöva välja modeller?

303
00:31:42,000 --> 00:31:44,119
 Kan den inte lita på sig själv?

304
00:31:44,119 --> 00:31:47,039
 Och det kommer i nästa release, tror jag.

305
00:31:47,039 --> 00:31:50,640
 att den automatiskt fattar vilken modell som är bäst för tomten.

306
00:31:50,720 --> 00:31:54,640
 Ja, den kommer att försvinna under under säkert det här halvåret.

307
00:31:54,720 --> 00:31:58,000
 Men ChatGPT4O med schemalagda aktiviteter,

308
00:32:00,000 --> 00:32:04,279
 Det kanske vi har gått igenom. Men bara lite snabbt.

309
00:32:04,319 --> 00:32:09,160
 Man kan då be ChatGPT påminna en om olika saker.

310
00:32:09,160 --> 00:32:13,599
 typ göra konkurrentanalys eller nånting.

311
00:32:13,759 --> 00:32:20,640
 Skicka till mig med den här promten varje dygn, typ.

312
00:32:20,640 --> 00:32:24,440
 Så det är en jäkligt bra grej, tycker jag.

313
00:32:24,440 --> 00:32:29,140
 Den stora frågan är, kan den här påminnelsen komma in i before sunset också?

314
00:32:29,140 --> 00:32:31,440
 Ja, exakt.

315
00:32:31,440 --> 00:32:37,079
 Och sen det här är också såhär, för oss så är det här super basic.

316
00:32:37,079 --> 00:32:42,000
 Men det är nog inte det för alla märkte jag när jag presenterade det här sist.

317
00:32:42,000 --> 00:32:47,359
 Men du kan också ladda upp filer, så du kan ladda upp en lokal fil.

318
00:32:47,519 --> 00:32:51,759
 Ladda upp en bild på dig. Ingenting funkar med ChatGPT nu.

319
00:33:00,000 --> 00:33:06,319
 Du kan ladda upp ett pdf-dokument och be den göra saker med det.

320
00:33:06,319 --> 00:33:11,880
 Sammanställa som en Excel eller fråga om dokumentets innehåll.

321
00:33:12,150 --> 00:33:18,150
 Nej, det var bara fyra, men det spelar väl ingen roll. Jag trodde inte att någon skulle...

322
00:33:18,150 --> 00:33:21,809
 Vi kör lite den här... Finger...

323
00:33:21,809 --> 00:33:24,849
 Jag är precis som AI.

324
00:33:24,849 --> 00:33:26,210
 Jag klarar inte av fem.

325
00:33:26,210 --> 00:33:28,930
 Precis. Klockan fyra eller sex.

326
00:33:29,089 --> 00:33:32,569
 Okej, fyra tips. Jag säger ett tips till.

327
00:33:32,569 --> 00:33:34,069
 Så att det blir 5.

328
00:33:34,069 --> 00:33:40,069
 Då kan jag nämligen skriva det i podden, vad den heter eller i beskrivningen.

329
00:33:40,069 --> 00:33:40,869
 Okej.

330
00:33:40,869 --> 00:33:43,069
 Nästa tips, det är det här.

331
00:33:43,069 --> 00:33:53,630
 Tänker du på inställningsfliken, då finns det lite olika saker här.

332
00:33:53,630 --> 00:33:56,630
 Då kan man faktiskt anpassa ChatGPT.

333
00:34:00,299 --> 00:34:08,300
 Och man kan skriva så här, hur ska ChatGPT tilltala dig?

334
00:34:08,300 --> 00:34:12,300
 Så det kan man skriva i här.

335
00:34:12,300 --> 00:34:25,989
 man också hitta ChatGPTs minne under inställningar och anpassning och minne.

336
00:34:30,000 --> 00:34:39,760
 Så hantera minnen. Som du ser så har ChatGPT lärt sig en hel del om mig under åren som jag har använt det.

337
00:34:39,760 --> 00:34:41,760
 att det här är bra att veta om Magnus.

338
00:34:41,760 --> 00:34:44,760
 Det här måste jag bara flika in.

339
00:34:44,760 --> 00:34:47,760
 Tänk om Spotify hade den här funktionen?

340
00:34:47,760 --> 00:34:52,760
 Jag minns när barnen var små och vi råkade lyssna på Marcus &amp; Martinus en sommar.

341
00:35:00,000 --> 00:35:06,179
 Och sen så var alla mina förslag från Discovery Weekly norska låtar.

342
00:35:06,179 --> 00:35:08,900
 Jag kunde inte ta bort det på något sätt.

343
00:35:30,000 --> 00:35:34,599
 "'Hasn intressed in humming birds?'"

344
00:35:41,000 --> 00:35:46,599
 Därför ska jag gå in på inkognito-mode när vi ska försöka repetera.

345
00:35:46,599 --> 00:35:48,119
 Ja, verkligen.

346
00:36:00,000 --> 00:36:01,079
 Den är inte klockren.

347
00:36:01,079 --> 00:36:05,519
 Det är skönt att jag kan dra ner dig i min AI-blues idag också.

348
00:36:05,519 --> 00:36:06,840
 Ja, exakt.

349
00:36:06,840 --> 00:36:09,760
 Sluta med det, nu ska jag visa något riktigt coolt här.

350
00:36:09,760 --> 00:36:18,639
 Jag vet inte, men vi har ett avsnitt där vi skriver att vi väcker gamla minnen.

351
00:36:18,639 --> 00:36:20,639
 Ja, det var min ambition.

352
00:36:20,639 --> 00:36:24,639
 Exakt. Men du misslyckades ganska hårt.

353
00:36:30,000 --> 00:36:34,239
 Verkligen. Och jag kommer inte ihåg vad den tjänsten hette.

354
00:36:34,239 --> 00:36:36,239
 Det gör jag faktiskt inte.

355
00:36:36,239 --> 00:36:41,360
 För jag tänkte att det måste funka.

356
00:36:41,360 --> 00:36:43,360
 Den som verkade bäst.

357
00:36:43,360 --> 00:36:47,360
 Och den heter Deep nostalja.

358
00:36:47,360 --> 00:36:56,360
 Deep nostalgi AI, turn old photos into videos, bring image to life.

359
00:36:57,429 --> 00:37:00,849
 Så jag gick in. Här får man också pröjsa först.

360
00:37:00,849 --> 00:37:04,050
 Jag tror att det kan ha varit den där jag testade.

361
00:37:04,050 --> 00:37:08,050
 Det ska bli jättespännande att se om den är bättre än övriga.

362
00:37:08,050 --> 00:37:15,050
 Jag tog ett basic-abonnemang, 15,90 dollar per månad.

363
00:37:15,050 --> 00:37:17,050
 Nej, vet du vad?

364
00:37:17,050 --> 00:37:19,050
 Du har inte köpt den här.

365
00:37:19,050 --> 00:37:28,050
 Nej men vad luriga de är! Pro-abonnemanget visas först och sen kommer Basic-abonnemanget.

366
00:37:28,050 --> 00:37:32,050
 Så jag råkade nog ta Pro-abonnemanget.

367
00:37:32,070 --> 00:37:38,670
 Roligt. Det där vill man ju inte ens lära sig av. Sådär vill man ju inte ha det.

368
00:37:38,750 --> 00:37:40,750
 Strunt samma.

369
00:37:40,750 --> 00:37:42,750
 Här finns det lite olika grejer.

370
00:37:42,750 --> 00:37:44,750
 3 tools.

371
00:37:44,750 --> 00:37:46,750
 Magic 2.

372
00:37:46,750 --> 00:37:50,750
 3-2s gör ditt foto bättre.

373
00:38:00,000 --> 00:38:09,000
 Du kan skapa färger till svartvita foton och sånt där. Jag har inte testat dem.

374
00:38:09,000 --> 00:38:14,300
 Fast Video Generator Image to Video. Jag vet faktiskt inte skillnaden mellan dem.

375
00:38:14,300 --> 00:38:21,300
 AI-hugg, AI-dans, AI-kissing, AI-cung-fu, AI-lip-sync.

376
00:38:21,300 --> 00:38:24,320
 Kan inte du säga 'eyah kangfu' på din gammelfarmor?

377
00:38:24,320 --> 00:38:30,559
 Faktum är att jag har gjort lite. Det tar ju en liten stund. Det tar typ 5 minuter att generera fram de här grejerna.

378
00:38:30,559 --> 00:38:35,559
 Så jag har faktiskt gjort lite olika som jag tänkte demonstrera nu faktiskt.

379
00:38:35,559 --> 00:38:36,559
 Oj, vad kul!

380
00:38:36,559 --> 00:38:40,559
 Och för er som lyssnar så är det här en videopodd som finns på Spotify.

381
00:38:40,559 --> 00:38:44,559
 Vi finns på alla andra plattformar också, men då är det bara audio.

382
00:38:44,559 --> 00:38:49,559
 Så för er som sitter i bilen nu, då kommer det här.

383
00:38:49,559 --> 00:38:51,559
 Ni får skip-forward om ni vill.

384
00:38:51,559 --> 00:38:53,119
 För nu kommer en del video här.

385
00:38:53,119 --> 00:38:56,119
 Men vi ska försöka förklara oss i bästa förmåga.

386
00:38:56,119 --> 00:38:58,119
 Så jag skriver här my videos.

387
00:38:58,119 --> 00:39:00,119
 Eller klickar på den.

388
00:39:00,119 --> 00:39:04,840
 Och här har jag nu rätt många videos.

389
00:39:04,840 --> 00:39:09,960
 Så då började jag med de uppenbara. Jag har ganska gamla släktingar.

390
00:39:09,960 --> 00:39:15,159
 Eller, de finns ju inte längre, de som föddes på 1800-talet och så där.

391
00:39:30,000 --> 00:39:37,119
 Men jag hade en väldigt gammal pappa, så min farfar föddes 1875.

392
00:39:37,119 --> 00:39:39,119
 Oj, oj, oj!

393
00:39:39,119 --> 00:39:40,599
 Det ser elegant ut.

394
00:39:40,619 --> 00:39:44,320
 Ja, verkligen. Han står vid en stor trappa.

395
00:39:44,340 --> 00:39:45,900
 Jag tror att han bodde i det där huset.

396
00:39:45,900 --> 00:39:48,900
 Precis, man skulle kunna bo där.

397
00:39:48,900 --> 00:39:55,900
 Ja, verkligen. Han var well off, duktig på det han gjorde.

398
00:40:00,000 --> 00:40:06,000
 Så jag gjorde en... Då laddade jag upp den här bilden på honom, och sen så...

399
00:40:06,000 --> 00:40:10,340
 Jag borde ju visa det också.

400
00:40:10,340 --> 00:40:16,780
 Så man droppar en bild. Den får vara max 4.5 meg, vilket var ett problem.

401
00:40:16,780 --> 00:40:20,440
 Det måste vara JPG, alltså de här vanliga.

402
00:40:20,440 --> 00:40:26,039
 Det får alltså inte vara Heik som är det filnamnet som...

403
00:40:26,039 --> 00:40:28,719
 Och jag får vara här under?

404
00:40:28,719 --> 00:40:30,420
 Ja, verkligen. Jag fattar inte det här.

405
00:40:30,420 --> 00:40:36,420
 lake. Ingen klarar av hake, men sen så får man en prompt.

406
00:40:36,630 --> 00:40:43,909
 Animate this image, bring it to life with subtle movements, While preshirving the original features.

407
00:40:44,500 --> 00:40:49,099
 Här kan man också suggest prompt, för att det är svårt att komma på prompt själv.

408
00:40:49,099 --> 00:40:50,900
 Och sen så Optimize prompt.

409
00:40:51,170 --> 00:40:55,530
 Och sen kan man visa hur mycket man vill att den ska följa den här prompten.

410
00:41:00,000 --> 00:41:03,000
 Och så genererar man och det kostar 1 credit.

411
00:41:03,000 --> 00:41:06,000
 Så du kan göra 5 sekunder eller 10 sekunder.

412
00:41:06,000 --> 00:41:09,000
 Så det är ganska straight forward.

413
00:41:09,000 --> 00:41:14,659
 är min gamla farfar Come to Life.

414
00:41:14,659 --> 00:41:17,579
 Så jag klickar på play nu och då ser du.

415
00:41:31,840 --> 00:41:42,909
 Du får nog köra igen för jag såg väldigt hackigt.

416
00:41:42,909 --> 00:41:44,909
 Just det.

417
00:41:44,909 --> 00:41:49,809
 Det var lite kul. Han rörde sig. En bild på min farmor som sitter och spelar piano.

418
00:42:00,000 --> 00:42:12,210
 Det är fint, eftersom jag sitter där. Nu sätter jag igång den här.

419
00:42:12,210 --> 00:42:14,210
 Det där var ju coolt!

420
00:42:14,210 --> 00:42:17,170
 så blev hon ju något slags, hon blev asiatisk i slutet.

421
00:42:30,000 --> 00:42:34,699
 Det var väl det som hände när jag testade den här tjänsten förut.

422
00:42:34,699 --> 00:42:42,500
 Jag skickade upp det på min gammelmormor och så fick hon nästan nazistsymboler

423
00:42:42,500 --> 00:42:44,000
 och så var det en helt annan kvinna.

424
00:42:44,000 --> 00:42:47,500
 Ja, just det. Men jag tycker ändå att den har blivit bättre.

425
00:42:47,500 --> 00:42:49,000
 Ja, verkligen. Det måste jag säga.

426
00:42:49,000 --> 00:42:51,960
 Det är coolt. Man ser att det är Nisse.

427
00:42:51,980 --> 00:42:58,980
 Ja, precis. Han förvandlas ju lite grann till Cornelis Vreeswijk här, när han vände sig om.

428
00:43:00,000 --> 00:43:03,079
 Men jag tyckte också att det var häftigt.

429
00:43:03,079 --> 00:43:04,679
 Jag har inte skickat det här till min mamma.

430
00:43:04,679 --> 00:43:06,679
 Jag vågade inte riktigt.

431
00:43:06,699 --> 00:43:15,579
 Och här är en bild på min farfar, min pappa och hans syskon som sitter på en flotte.

432
00:43:15,579 --> 00:43:21,719
 I sjö... Ull... Trettiotalet eller någonting.

433
00:43:21,719 --> 00:43:29,719
 Och det är coolt, och vattnet är fantastiskt. Man ser det glittra.

434
00:43:30,429 --> 00:43:32,909
 Så det här var ju coolt.

435
00:43:32,989 --> 00:43:36,429
 Sen lyckades jag inte hela tiden, utan ibland funkar det inte.

436
00:43:36,510 --> 00:43:38,429
 Som här till exempel.

437
00:43:38,429 --> 00:43:44,570
 Här blir det bara att den zoomar in fotografiet.

438
00:43:44,570 --> 00:43:51,050
 Så jag vet inte riktigt vad som är kriterierna för att lyckas med det här, om det är nånting med upplösningen eller så.

439
00:44:00,369 --> 00:44:12,369
 Men sen gick jag vidare här. Det finns en Hugging-funktion där makes the two people in the photo hug each other.

440
00:44:12,369 --> 00:44:15,090
 med en bild på min pappa och sen en bild på min son.

441
00:44:15,090 --> 00:44:20,849
 De har aldrig träffats. Min pappa dog ju innan min äldste son föddes.

442
00:44:20,849 --> 00:44:26,809
 Och då kan man liksom... Enligt den här ska man kunna få dem att kramas.

443
00:44:30,000 --> 00:44:39,519
 Så jag laddar upp två bilder och sen trycker jag på play.

444
00:44:39,519 --> 00:44:42,380
 Nej, han kramar inte min son heller.

445
00:44:42,380 --> 00:44:44,900
 Vilken tur alltså, annars hade jag...

446
00:44:44,900 --> 00:44:52,380
 Jag försöker igen med en annan bild, men det går inte alls.

447
00:45:00,000 --> 00:45:09,730
 Sen gav jag upp där, men sen fanns det en kyssfunktion:

448
00:45:09,730 --> 00:45:12,050
 "Make the two people in the picture kiss."

449
00:45:12,050 --> 00:45:13,750
 kul att du såg så fräsch ut.

450
00:45:14,019 --> 00:45:19,780
 Det var lite svårt att hitta bilder som inte var hake, så jag ber om ursäkt.

451
00:45:30,000 --> 00:45:37,719
 Det här var den enda bilden vi hade på dig. Jag antecknar det här.

452
00:45:37,719 --> 00:45:46,420
 Jag gillar ändå AI:s tolkning av hur jag ser ut.

453
00:45:46,420 --> 00:45:52,420
 Men det här är ju inte bra. Det är ingen dålig kyss faktiskt.

454
00:45:52,420 --> 00:45:55,420
 Nej, men det såg ju väldigt naturligt ut.

455
00:45:55,420 --> 00:45:59,280
 Vad som hände för er som lyssnar var att det var en bild på Fredrik

456
00:45:59,280 --> 00:46:02,199
 Och sen bredvid Fredrik var det en bild på mig.

457
00:46:02,199 --> 00:46:12,460
 Och sen så vänder jag mig om och så dyker det upp en man i min bild som jag kysser.

458
00:46:12,460 --> 00:46:18,460
 Men det måste man ändå säga, rörelsen där du vänder dig.

459
00:46:30,400 --> 00:46:33,360
 Den är bra.

460
00:46:33,360 --> 00:46:37,360
 Det är ju jag. Så där ser jag ut.

461
00:46:37,360 --> 00:46:42,119
 Jag vill inte titta på när jag kysser den här okände mannen mer.

462
00:46:42,119 --> 00:46:45,039
 Det är dig som jag har tänkt att vi skulle se.

463
00:46:45,039 --> 00:46:47,039
 Det är mig du vill kyssa.

464
00:46:47,039 --> 00:46:49,599
 Ja, exakt. Jag tänkte att man skulle kunna ladda upp tjejer där.

465
00:46:49,599 --> 00:46:52,599
 Det är fri jakt på mig, så att säga.

466
00:46:54,599 --> 00:46:56,599
 Sådär, nu testar vi igen.

467
00:46:59,599 --> 00:47:01,599
 Ja, men det där har nog, tycker jag.

468
00:47:02,800 --> 00:47:12,800
 Det där såg inte ut som på exemplen, men det är väldigt effektivt.

469
00:47:12,800 --> 00:47:20,199
 Kanske ingen kyssisk användning är en slutscen i en Hollywoodfilm.

470
00:47:20,360 --> 00:47:21,800
 Nej.

471
00:47:21,960 --> 00:47:27,360
 Men vardagsrealism är det väl, frånsett att vi befinner oss i olika miljöer

472
00:47:30,000 --> 00:47:32,000
 som de inte lyckas gifta ihop.

473
00:47:32,000 --> 00:47:36,000
 Nej, men ändå lyckas lite granna.

474
00:47:36,000 --> 00:47:42,000
 Där gav jag upp kyssexemplet.

475
00:47:42,000 --> 00:47:51,909
 Jag tycker det här var ganska kul. Då ska vi... Två sekunder bara.

476
00:48:30,000 --> 00:48:38,909
 För skit för att jag djurplågar av mina barn.

477
00:48:38,909 --> 00:48:45,510
 Men sen fortsätter jag med ninjaversionen av det här. Jag tänkte att min farfar skulle bli ninja.

478
00:48:45,510 --> 00:48:47,510
 Ja. Coolt.

479
00:48:47,510 --> 00:48:53,960
 Det ser ut så här.

480
00:48:55,219 --> 00:48:56,920
 Farfar upp i dagen?

481
00:49:00,340 --> 00:49:04,940
 Han går från att stå vid sin stora trappa

482
00:49:04,940 --> 00:49:09,840
 till att bli någon slags kanfue-champion från Japan.

483
00:49:09,840 --> 00:49:14,940
 din svensexa för ett antal år sedan.

484
00:49:14,940 --> 00:49:17,079
 Nu är den redan lite omgjord av AI som du ser.

485
00:49:17,079 --> 00:49:26,139
 Men så gjorde jag ninjavarianten av alla som var med på sändsexan.

486
00:49:26,139 --> 00:49:27,420
 Ja, det blev inte jättebra.

487
00:49:27,420 --> 00:49:30,739
 Men det är roligt att se folk i ninjor.

488
00:49:30,739 --> 00:49:33,460
 Så det var väl kanske en topp.

489
00:49:33,980 --> 00:49:37,659
 Slutligen har jag en fin bild på dig här.

490
00:49:37,679 --> 00:49:40,199
 Vad är det där ifrån?

491
00:49:40,199 --> 00:49:43,840
 Det är nog från när vi var på konferens.

492
00:49:43,840 --> 00:49:46,039
 Du har fått en biff här.

493
00:49:46,039 --> 00:49:48,280
 Biff och bea. Då blev alla glada.

494
00:49:48,280 --> 00:49:51,760
 Och så skrev jag att du skulle skratta galet.

495
00:49:52,320 --> 00:50:00,000
 Så vi sätter igång.

496
00:50:00,000 --> 00:50:02,000
 Såg du eller?

497
00:50:02,139 --> 00:50:06,889
 Den hänger inte riktigt med.

498
00:50:07,090 --> 00:50:09,170
 Nu får du köra igen.

499
00:50:09,170 --> 00:50:17,940
 Nu ser jag bara en bild.

500
00:50:17,940 --> 00:50:20,519
 Jag vet inte om du ser det här?

501
00:50:20,519 --> 00:50:25,019
 Jag ser ungefär.

502
00:50:30,000 --> 00:50:33,400
 Och jag har helt andra tänder än vad jag har, såklart.

503
00:50:33,400 --> 00:50:37,599
 Du blir en helt annan människa.

504
00:50:37,599 --> 00:50:44,219
 era föräldrar eller något sånt där med en bild på mormor i svartvitt.

505
00:50:44,239 --> 00:50:48,639
 Som en ninja. Då kan ni gå in här.

506
00:50:48,639 --> 00:50:52,440
 Lätt värt tycker jag, 180 spänn att få se de här.

507
00:50:52,440 --> 00:50:58,039
 Det är ju ändå folk som har försvunnit från denna världen. Alltså vissa av dem.

508
00:51:00,500 --> 00:51:11,500
 Det känns som en tjänst, jag vet inte om jag pratar om det i podden, men ett problem som majoriteten av alla AI-tjänster har är ju Churn.

509
00:51:11,500 --> 00:51:18,460
 be om att få folk som signar upp, men stannar du månad 2 i en sådan här tjänst?

510
00:51:18,460 --> 00:51:19,820
 Nej, nej, aldrig.

511
00:51:30,000 --> 00:51:34,320
 Jag har redan sagt upp, hoppas jag.

512
00:51:34,480 --> 00:51:36,960
 Nej, det hade jag inte.

513
00:51:37,119 --> 00:51:41,440
 Jag tror att vi kommer att se en skillnad där i framtiden

514
00:51:41,440 --> 00:51:45,199
 Jag tycker alltid man brukar se det. Jag ska bara ta flygbranschen.

515
00:51:45,199 --> 00:51:50,679
 Kommer du ihåg när SAS inte erbjöd enkelresor?

516
00:51:50,679 --> 00:51:53,920
 Man var tvungen att boka tur och retur.

517
00:51:54,000 --> 00:51:58,480
 Jag tycker alla affärsmodeller som inte tänker på kunden i första hand,

518
00:52:00,000 --> 00:52:05,599
 där det bara är oförståeligt varför man skulle ha det här som en SAS-tjänst.

519
00:52:05,599 --> 00:52:11,159
 Ett år vill jag fortfarande ladda upp tio bilder i månaden på gamla släktingar.

520
00:52:11,159 --> 00:52:17,199
 Nej, det funkar inte så. Jag tror nog att det kommer ändras, utan tvekan.

521
00:52:17,199 --> 00:52:23,199
 Men du, jag har en till tjänst också. Jag har värsta bonansen den här gången.

522
00:52:23,199 --> 00:52:32,079
 Och jag var inne på Hagen för att fixa en grej som också är en härlig, bra tjänst för att skapa AI-avatarier.

523
00:52:32,079 --> 00:52:33,579
 Just det.

524
00:52:33,579 --> 00:52:37,260
 Och jag brukar alltid gå in och titta på LABS.

525
00:52:37,260 --> 00:52:42,260
 Både Hajen och Eleven Labs har något som heter Labs eller Studio

526
00:52:42,260 --> 00:52:49,159
 där man kan hitta deras nya betagrejer som de håller på att testa.

527
00:52:49,159 --> 00:52:58,039
 Vi har testat Interactive avatar, där du träffar en avatar.

528
00:53:00,000 --> 00:53:03,079
 Det var där ute för Viveca, typ. Ja, just det.

529
00:53:03,079 --> 00:53:06,019
 Som ett Zoom-möte.

530
00:53:07,179 --> 00:53:08,659
 Hej, Magnus.

531
00:53:09,699 --> 00:53:11,780
 Låt oss prata om det. Vad ska jag göra?

532
00:53:11,780 --> 00:53:19,340
 Det var ganska roligt, men då såg jag en ny funktion igår.

533
00:53:19,340 --> 00:53:32,340
 videopodcast. Lite snyggare uttal. Och då klickar man på den då skickar man in en pdf här bara.

534
00:53:33,159 --> 00:53:38,719
 Så du laddar upp en pdf och sen skapar den en videopodcast utifrån den här pdf:en.

535
00:53:39,059 --> 00:53:48,219
 Så det här är väldigt mycket som Google Notebook LM som jag har visat. Men det här är då med video.

536
00:53:48,219 --> 00:53:49,219
 Ja, vad coolt.

537
00:53:49,360 --> 00:53:55,079
 Och jag håller ju på att skriva en bok, och den här boken har jag kommit på vad den ska heta. Den ska heta...

538
00:54:00,210 --> 00:54:06,449
 Nu kommer jag inte ihåg vad som hände. Alltså, vad var det som hände?

539
00:54:07,809 --> 00:54:10,489
 Det måste du göra utan mig.

540
00:54:10,489 --> 00:54:19,250
 Den boken. Och sen klickar man på "Generate video" och då får man välja vilken avatar man vill använda sig av.

541
00:54:19,250 --> 00:54:22,230
 Man kan ju inte använda sin egen. Än så länge.

542
00:54:31,039 --> 00:54:38,039
 Jag har fixat två videopodcasts, en på svenska och en på engelska. Du får höra den på svenska först då.

543
00:54:38,039 --> 00:54:44,539
 Vad kul! Härligt! Då kör vi!

544
00:54:44,539 --> 00:54:50,679
 Jo han satt på sitt kontor i Värmland, hade precis lanserat sin textplattform och så släpper OpenAI Chat Jeopity.

545
00:54:50,940 --> 00:54:53,739
 Det vände upp och ner på allt för honom.

546
00:54:54,000 --> 00:54:56,300
 Oj det måste ha känts som en rejäl kalldusch?

547
00:55:00,110 --> 00:55:03,110
 Ja, verkligen. Men han gav inte upp istället.

548
00:55:03,110 --> 00:55:06,110
 Han pivotade och integrerade AIN i sin tjänst.

549
00:55:06,110 --> 00:55:07,110
 Det kräver mod.

550
00:55:07,110 --> 00:55:08,110
 Imponerande.

551
00:55:08,110 --> 00:55:11,110
 Varför tvekade han inte? Det måste ha varit en risk.

552
00:55:11,110 --> 00:55:13,110
 Jo, säkert.

553
00:55:13,110 --> 00:55:14,389
 Ignorera det.

554
00:55:14,389 --> 00:55:17,969
 Nej, sant. Men många är rädda för att AI ska ta deras jobb.

555
00:55:17,969 --> 00:55:21,329
 Absolut, men det är som med alla teknologiska språng.

556
00:55:21,329 --> 00:55:24,530
 Vi förlorade hästskötare, men fick bilmekaniker.

557
00:55:24,530 --> 00:55:25,389
 Bra poäng.

558
00:55:25,389 --> 00:55:27,289
 Men tror du att alla kan anpassa sig?

559
00:55:27,289 --> 00:55:28,510
 Det är en utmaning.

560
00:55:28,510 --> 00:55:32,190
 Men kanske är det vårt ansvar att hjälpa varandra att utvecklas.

561
00:55:32,190 --> 00:55:39,980
 Men kreativiteten då? Om AI kan skapa konst och musik, vad skapar...

562
00:55:39,980 --> 00:55:49,420
 Jag fattar, på vissa grejer, ibland så fattar jag inte varför de lägger upp.

563
00:55:49,420 --> 00:55:52,420
 Jag tänkte så här, okej, det här suger verkligen.

564
00:55:52,420 --> 00:55:55,420
 Det är coolt på ett sätt.

565
00:56:00,139 --> 00:56:10,139
 Man ser ju att de har perfekt läppsynk och så, men svenskan är lite konstig.

566
00:56:10,139 --> 00:56:13,539
 att det verkligen låter som en podcast.

567
00:56:13,539 --> 00:56:17,539
 Det här är inte framme alls, men det är väldigt underhållande.

568
00:56:17,539 --> 00:56:24,539
 Jag tänkte geagen en chans till att göra det här på engelska.

569
00:56:25,320 --> 00:56:31,320
 Så jag valde lite andra folk här, men samma fil.

570
00:56:32,260 --> 00:56:34,820
 Så vi kör igång.

571
00:56:34,820 --> 00:56:40,820
 Så har du märkt hur AI bara exploderade på scenen på sistone?

572
00:56:40,820 --> 00:56:43,820
 Det är som om vi gick till sömnen och vaknade upp i en ny värld.

573
00:56:43,820 --> 00:56:45,820
 Absolut, det har varit en ganska stor resa.

574
00:56:45,820 --> 00:56:49,179
 What's your biggest take away from this suddenly skift?

575
00:56:49,179 --> 00:56:52,340
 Well, it's like we were working on our own revolutionary platform.

576
00:56:52,340 --> 00:56:56,340
 Och sen kom GPT med och förändrade spelet helt.

577
00:56:56,340 --> 00:56:59,139
 Du menar när OpenAI släppte den och kokade in industrin?

578
00:56:59,139 --> 00:57:05,139
 Exakt, vi hade precis lanserat vår textplattform Celebrating and All, och plötsligt insåg vi att vi var tvungna att piva det snabbt.

579
00:57:05,139 --> 00:57:08,460
 Så du bestämde dig för att integrera AI i stället för att konkurrera mot den.

580
00:57:08,460 --> 00:57:09,079
 Ja, det gjorde vi.

581
00:57:09,079 --> 00:57:13,579
 Det är som att försöka återuppfinna hjulet när du kunde bygga ett bättre fordon med det nya tekniket.

582
00:57:13,579 --> 00:57:14,380
 Lätt!

583
00:57:14,380 --> 00:57:17,860
 Tycker du att folk förstår hur transformativ AI kommer att vara?

584
00:57:17,860 --> 00:57:19,219
 Ärligt talat, jag är inte säker.

585
00:57:19,219 --> 00:57:24,599
 Endast cirka 29% har använt generativ AI, men snart blir det lika vanligt som elektricitet.

586
00:57:24,599 --> 00:57:26,960
 Det är både fascinerande och lite skrämmande.

587
00:57:26,960 --> 00:57:30,559
 Tycker du att vi normaliserar dessa tech-mirakler för snabbt?

588
00:57:30,559 --> 00:57:32,940
 Exactly, we get amazed that first,

589
00:57:32,940 --> 00:57:35,099
 but then we start nit picking minor issues.

590
00:57:35,099 --> 00:57:39,630
 Ah, you're blown away?

591
00:57:39,630 --> 00:57:44,769
 Nej, men som med allt annat så ser man ju...

592
00:57:44,769 --> 00:57:46,469
 Det här är första utkastet,

593
00:57:46,469 --> 00:57:50,710
 Det kommer ju att bli otroligt på sikt.

594
00:57:50,710 --> 00:57:56,550
 Ja, absolut. Var det inte lite kul att den killen började prata indisk?

595
00:58:00,000 --> 00:58:03,679
 Jag tyckte han var behaglig på ett obehagligt sätt.

596
00:58:03,840 --> 00:58:06,639
 På ett lobotomerat sätt?

597
00:58:06,639 --> 00:58:10,980
 åker och går i kloster i tolv år och sedan kommer tillbaka

598
00:58:10,980 --> 00:58:12,019
 och föreläser om det.

599
00:58:13,659 --> 00:58:15,880
 Alltså, den känslan.

600
00:58:15,880 --> 00:58:21,880
 I want to tell you about what happened in this celibass?

601
00:58:30,239 --> 00:58:36,400
 Ja, men det där tyckte jag ändå rörde om i grytan.

602
00:58:36,400 --> 00:58:37,559
 Det var kul.

603
00:58:37,559 --> 00:58:40,199
 Ja, det var kul.

604
00:58:40,199 --> 00:58:43,280
 Svenskan kom alltid lite på efterkälken.

605
00:58:43,280 --> 00:58:46,159
 Men det var underhållande om inte annat.

606
00:58:46,159 --> 00:58:50,159
 ha nån subscruption, utan man kan göra det här själv.

607
00:58:50,159 --> 00:58:53,000
 Så det är bara att gå in och göra det.

608
00:59:00,000 --> 00:59:05,039
 Det var det som jag hade. Har du nåt mer, Fredrik?

609
00:59:05,119 --> 00:59:07,559
 Nej, jag tror inte det. Jag tar nya tag i nästa vecka.

610
00:59:07,559 --> 00:59:12,199
 Våra AI-föreläsningar. Hör av er om ni är intresserade av att vi kommer att köra en

611
00:59:12,199 --> 00:59:14,840
 inspirationsföreläsning på en eller tre timmar.

612
00:59:14,960 --> 00:59:17,960
 Vi gör också sådana här AI-assistenter så hör av er.

613
00:59:18,119 --> 00:59:21,400
 Gå in på veckans punkt AI om ni vill ha kontaktuppgifter.

614
00:59:21,559 --> 00:59:25,824
 Annars så säger vi ha en fin, ha det bra.

